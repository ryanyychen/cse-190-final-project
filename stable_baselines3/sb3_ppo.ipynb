{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7a04ef3",
   "metadata": {},
   "source": [
    "# Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1882261",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = \"./models/ppo/ppo\"\n",
    "TENSORBOARD_LOG_DIR = \"./models/ppo/logs\"\n",
    "IMAGE_TAG = \"ppo_rewards\"\n",
    "IMAGE_DIR = \"./images/ppo\"\n",
    "RUNS_FILE = \"./models/ppo/ppo_success_runs.pkl\"\n",
    "\n",
    "#### ENV CONFIGS ####\n",
    "CONFIG = {\n",
    "    \"observation\": {\n",
    "        \"type\": \"Kinematics\",\n",
    "        \"vehicles_count\": 15,  # Number of other vehicles to observe\n",
    "        \"features\": [\"presence\", \"x\", \"y\", \"vx\", \"vy\"],  # Observe position and velocity\n",
    "        \"features_range\": {\n",
    "            \"x\": [-100, 100],\n",
    "            \"y\": [-100, 100],\n",
    "            \"vx\": [-10, 10],\n",
    "            \"vy\": [-10, 10]\n",
    "        },\n",
    "        \"absolute\": False,\n",
    "        \"clip\": False,\n",
    "        \"normalize\": False\n",
    "    },\n",
    "    \"action\": {\n",
    "        \"type\": \"DiscreteMetaAction\",  # Keep simple, 5 discrete actions\n",
    "    },\n",
    "    \"simulation_frequency\": 10,\n",
    "    \"policy_frequency\": 10,\n",
    "    \"destination\": \"o1\",\n",
    "    \"initial_vehicle_count\": 20,\n",
    "    \"spawn_probability\": 0.8,\n",
    "    \"ego_spacing\": 25,\n",
    "    \"initial_lane_id\": None,\n",
    "    \"controlled_vehicles\": 1,\n",
    "    \"duration\": 15,  # seconds\n",
    "    \"vehicles_density\": 1.0,\n",
    "    \"screen_width\": 600,\n",
    "    \"screen_height\": 600,\n",
    "    \"centering_position\": [0.5, 0.6],\n",
    "    \"scaling\": 5.5 * 1.3,\n",
    "    \"normalize_reward\": False\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6581d711",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4633e953",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/preranagowda/Desktop/cse-190-final-project/.venv/lib/python3.13/site-packages/pygame/pkgdata.py:25: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import resource_stream, resource_exists\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import torch\n",
    "import pickle\n",
    "import random\n",
    "import gymnasium as gym\n",
    "\n",
    "from fvcore.nn import FlopCountAnalysis\n",
    "\n",
    "from stable_baselines3 import A2C, PPO, SAC\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3.common.callbacks import ProgressBarCallback\n",
    "\n",
    "from custom_intersection_env import CustomIntersectionEnv\n",
    "from custom_training_callback import RewardTrackingCallback"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a1ce09",
   "metadata": {},
   "source": [
    "# Register Env with Gymnasium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ca02c7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/preranagowda/Desktop/cse-190-final-project/.venv/lib/python3.13/site-packages/gymnasium/envs/registration.py:644: UserWarning: \u001b[33mWARN: Overriding environment custom-intersection-v0 already in registry.\u001b[0m\n",
      "  logger.warn(f\"Overriding environment {new_spec.id} already in registry.\")\n"
     ]
    }
   ],
   "source": [
    "gym.envs.registration.register(\n",
    "    id='custom-intersection-v0',\n",
    "    entry_point='custom_intersection_env:CustomIntersectionEnv',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e8a92da",
   "metadata": {},
   "source": [
    "# Create + Wrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "40176e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"custom-intersection-v0\", render_mode='rgb_array', config=CONFIG)\n",
    "env = DummyVecEnv([lambda: env])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff4f8a3f",
   "metadata": {},
   "source": [
    "# Set up Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "109d5026",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PPO(\n",
    "    policy=\"MlpPolicy\",\n",
    "    env=env,\n",
    "    n_steps=5,\n",
    "    batch_size=5,\n",
    "    learning_rate=7e-4,\n",
    "    gamma=0.99,\n",
    "    gae_lambda=1.0,\n",
    "    ent_coef=0.01,\n",
    "    vf_coef=0.5,\n",
    "    max_grad_norm=0.5,\n",
    "    normalize_advantage=False,\n",
    "    tensorboard_log=TENSORBOARD_LOG_DIR,\n",
    "    verbose=0,\n",
    "    device=\"cpu\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3217a106",
   "metadata": {},
   "source": [
    "# Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "85178a94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f341dd4a93749bd87416e4b20ca0e44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e276a9784b954a7199c3b9d4bdd89bce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "142ab4f196f44c83bb7fed194e5b6b91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "reward_callback = RewardTrackingCallback(\n",
    "    tag=IMAGE_TAG,\n",
    "    path_dir=IMAGE_DIR\n",
    ")\n",
    "\n",
    "destinations = [\"o1\", \"o2\", \"o3\"]\n",
    "steps = [20000, 20000, 20000]\n",
    "\n",
    "for dest, steps in zip(destinations, steps):\n",
    "    config = CONFIG.copy()\n",
    "    config[\"destination\"] = dest  # Change destination for each training phase\n",
    "    env = gym.make(\"custom-intersection-v0\", render_mode='rgb_array', config=config)\n",
    "    env = DummyVecEnv([lambda: env])\n",
    "    model.set_env(env)  # Update the model with the new environment\n",
    "    model.learn(\n",
    "        total_timesteps=steps,\n",
    "        callback=[ProgressBarCallback(), reward_callback]\n",
    "    )\n",
    "    reward_callback.start_new_phase()\n",
    "reward_callback.save_all_plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "209a066c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c1fc460a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PPO.load(MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "310b94d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1 finished, total reward: -25.0, destination: o1\n",
      "Episode 2 finished, total reward: -25.0, destination: o2\n",
      "Episode 3 finished, total reward: 50.0, destination: o1\n",
      "Episode 4 finished, total reward: -25.0, destination: o1\n",
      "Episode 5 finished, total reward: 50.0, destination: o2\n",
      "Episode 6 finished, total reward: -25.0, destination: o3\n",
      "Episode 7 finished, total reward: -25.0, destination: o2\n",
      "Episode 8 finished, total reward: -25.0, destination: o3\n",
      "Episode 9 finished, total reward: -25.0, destination: o2\n",
      "Episode 10 finished, total reward: 50.0, destination: o1\n",
      "Episode 11 finished, total reward: 50.0, destination: o1\n",
      "Episode 12 finished, total reward: -25.0, destination: o2\n",
      "Episode 13 finished, total reward: -25.0, destination: o2\n",
      "Episode 14 finished, total reward: -25.0, destination: o3\n",
      "Episode 15 finished, total reward: -25.0, destination: o2\n",
      "Episode 16 finished, total reward: -25.0, destination: o3\n",
      "Episode 17 finished, total reward: -25.0, destination: o2\n",
      "Episode 18 finished, total reward: 50.0, destination: o1\n",
      "Episode 19 finished, total reward: -25.0, destination: o2\n",
      "Episode 20 finished, total reward: -25.0, destination: o1\n",
      "Episode 21 finished, total reward: -25.0, destination: o1\n",
      "Episode 22 finished, total reward: -25.0, destination: o3\n",
      "Episode 23 finished, total reward: -25.0, destination: o1\n",
      "Episode 24 finished, total reward: 50.0, destination: o2\n",
      "Episode 25 finished, total reward: 50.0, destination: o2\n",
      "Episode 26 finished, total reward: -25.0, destination: o1\n",
      "Episode 27 finished, total reward: -50.0, destination: o3\n",
      "Episode 28 finished, total reward: -25.0, destination: o3\n",
      "Episode 29 finished, total reward: 50.0, destination: o2\n",
      "Episode 30 finished, total reward: 50.0, destination: o1\n",
      "Episode 31 finished, total reward: -25.0, destination: o1\n",
      "Episode 32 finished, total reward: -25.0, destination: o2\n",
      "Episode 33 finished, total reward: 50.0, destination: o1\n",
      "Episode 34 finished, total reward: -25.0, destination: o3\n",
      "Episode 35 finished, total reward: -25.0, destination: o3\n",
      "Episode 36 finished, total reward: 50.0, destination: o3\n",
      "Episode 37 finished, total reward: -25.0, destination: o1\n",
      "Episode 38 finished, total reward: -25.0, destination: o1\n",
      "Episode 39 finished, total reward: -25.0, destination: o2\n",
      "Episode 40 finished, total reward: 50.0, destination: o2\n",
      "Episode 41 finished, total reward: 50.0, destination: o2\n",
      "Episode 42 finished, total reward: -25.0, destination: o1\n",
      "Episode 43 finished, total reward: -25.0, destination: o1\n",
      "Episode 44 finished, total reward: -25.0, destination: o2\n",
      "Episode 45 finished, total reward: -25.0, destination: o2\n",
      "Episode 46 finished, total reward: -25.0, destination: o2\n",
      "Episode 47 finished, total reward: -25.0, destination: o2\n",
      "Episode 48 finished, total reward: 50.0, destination: o1\n",
      "Episode 49 finished, total reward: -25.0, destination: o1\n",
      "Episode 50 finished, total reward: -25.0, destination: o3\n",
      "Episode 51 finished, total reward: -25.0, destination: o2\n",
      "Episode 52 finished, total reward: -25.0, destination: o2\n",
      "Episode 53 finished, total reward: -25.0, destination: o2\n",
      "Episode 54 finished, total reward: -25.0, destination: o2\n",
      "Episode 55 finished, total reward: -25.0, destination: o1\n",
      "Episode 56 finished, total reward: 50.0, destination: o3\n",
      "Episode 57 finished, total reward: 50.0, destination: o1\n",
      "Episode 58 finished, total reward: -25.0, destination: o2\n",
      "Episode 59 finished, total reward: -25.0, destination: o3\n",
      "Episode 60 finished, total reward: -25.0, destination: o2\n",
      "Episode 61 finished, total reward: 50.0, destination: o1\n",
      "Episode 62 finished, total reward: -25.0, destination: o1\n",
      "Episode 63 finished, total reward: -25.0, destination: o3\n",
      "Episode 64 finished, total reward: -25.0, destination: o3\n",
      "Episode 65 finished, total reward: -50.0, destination: o2\n",
      "Episode 66 finished, total reward: 50.0, destination: o1\n",
      "Episode 67 finished, total reward: -25.0, destination: o3\n",
      "Episode 68 finished, total reward: -25.0, destination: o2\n",
      "Episode 69 finished, total reward: -25.0, destination: o3\n",
      "Episode 70 finished, total reward: 50.0, destination: o1\n",
      "Episode 71 finished, total reward: -25.0, destination: o1\n",
      "Episode 72 finished, total reward: -25.0, destination: o1\n",
      "Episode 73 finished, total reward: -25.0, destination: o3\n",
      "Episode 74 finished, total reward: -25.0, destination: o2\n",
      "Episode 75 finished, total reward: -25.0, destination: o1\n",
      "Episode 76 finished, total reward: 50.0, destination: o1\n",
      "Episode 77 finished, total reward: -25.0, destination: o1\n",
      "Episode 78 finished, total reward: -25.0, destination: o2\n",
      "Episode 79 finished, total reward: -25.0, destination: o2\n",
      "Episode 80 finished, total reward: 50.0, destination: o2\n",
      "Episode 81 finished, total reward: -25.0, destination: o3\n",
      "Episode 82 finished, total reward: -25.0, destination: o2\n",
      "Episode 83 finished, total reward: -25.0, destination: o3\n",
      "Episode 84 finished, total reward: -25.0, destination: o2\n",
      "Episode 85 finished, total reward: -25.0, destination: o3\n",
      "Episode 86 finished, total reward: -25.0, destination: o2\n",
      "Episode 87 finished, total reward: -25.0, destination: o1\n",
      "Episode 88 finished, total reward: -25.0, destination: o1\n",
      "Episode 89 finished, total reward: -25.0, destination: o1\n",
      "Episode 90 finished, total reward: -25.0, destination: o3\n",
      "Episode 91 finished, total reward: 50.0, destination: o1\n",
      "Episode 92 finished, total reward: -25.0, destination: o1\n",
      "Episode 93 finished, total reward: -25.0, destination: o1\n",
      "Episode 94 finished, total reward: -25.0, destination: o1\n",
      "Episode 95 finished, total reward: -25.0, destination: o3\n",
      "Episode 96 finished, total reward: -25.0, destination: o1\n",
      "Episode 97 finished, total reward: -25.0, destination: o1\n",
      "Episode 98 finished, total reward: 50.0, destination: o1\n",
      "Episode 99 finished, total reward: -25.0, destination: o3\n",
      "Episode 100 finished, total reward: -25.0, destination: o2\n",
      "Total collisions: 77 out of 100 episodes\n",
      "Total destination arrivals: 23 out of 100 episodes\n",
      "FLOPS per successful episode: 1.1e+06\n"
     ]
    }
   ],
   "source": [
    "collisions = 0\n",
    "destination_arrivals = 0\n",
    "success_count = 0\n",
    "successful_flopcount = 0\n",
    "episodes = 100\n",
    "\n",
    "# Store successful runs for rendering\n",
    "successful_runs = []\n",
    "\n",
    "for eps in range(100):\n",
    "    config = CONFIG.copy()\n",
    "    config[\"destination\"] = \"o\" + str(random.randint(1, 3))\n",
    "    env = gym.make(\"custom-intersection-v0\", render_mode='rgb_array', config=config)\n",
    "\n",
    "    obs, _ = env.reset()\n",
    "    episode_flops = 0\n",
    "    done = False\n",
    "    truncated = False\n",
    "    episode_reward = 0\n",
    "    trajectory = []\n",
    "\n",
    "    while not (done or truncated):\n",
    "        # Flop Counting\n",
    "        input_tensor, _ = model.policy.obs_to_tensor(obs)\n",
    "        flops = FlopCountAnalysis(model.policy, input_tensor)\n",
    "        flops.unsupported_ops_warnings(False)\n",
    "        flops = flops.total()\n",
    "        episode_flops += flops\n",
    "\n",
    "        action, _states = model.predict(obs, deterministic=True)\n",
    "        trajectory.append((obs, action))  # Save for later render if successful\n",
    "        obs, reward, done, truncated, info = env.step(action)\n",
    "        episode_reward += reward\n",
    "    \n",
    "    crashed = info.get(\"crashed\", False)\n",
    "    arrived = info.get(\"arrived\", False)\n",
    "    if crashed:\n",
    "        collisions += 1\n",
    "    if arrived:\n",
    "        destination_arrivals += 1\n",
    "    if (not crashed) and arrived:\n",
    "        success_count += 1\n",
    "        successful_flopcount += episode_flops\n",
    "        successful_runs.append((config.copy(), trajectory))\n",
    "\n",
    "    print(f\"Episode {eps + 1} finished, total reward: {episode_reward}, destination: {config['destination']}\")\n",
    "    time.sleep(1)\n",
    "\n",
    "print(f\"Total collisions: {collisions} out of {episodes} episodes\")\n",
    "print(f\"Total destination arrivals: {destination_arrivals} out of {episodes} episodes\")\n",
    "if success_count > 0:\n",
    "    print(f\"FLOPS per successful episode: {successful_flopcount / success_count:.2}\")\n",
    "else:\n",
    "    print(\"No successful episodes.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "628a0d12",
   "metadata": {},
   "source": [
    "# Save and Load Successful Runs\n",
    "# Then Render "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dd231bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(RUNS_FILE, \"wb\") as f:\n",
    "    pickle.dump(successful_runs, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a6f0e1a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(RUNS_FILE, \"rb\") as f:\n",
    "    successful_runs = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "adcb4f19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Rendering successful episode 1\n",
      "\n",
      "Rendering successful episode 2\n",
      "\n",
      "Rendering successful episode 3\n",
      "\n",
      "Rendering successful episode 4\n",
      "\n",
      "Rendering successful episode 5\n",
      "\n",
      "Rendering successful episode 6\n",
      "\n",
      "Rendering successful episode 7\n",
      "\n",
      "Rendering successful episode 8\n",
      "\n",
      "Rendering successful episode 9\n",
      "\n",
      "Rendering successful episode 10\n",
      "\n",
      "Rendering successful episode 11\n",
      "\n",
      "Rendering successful episode 12\n",
      "\n",
      "Rendering successful episode 13\n",
      "\n",
      "Rendering successful episode 14\n",
      "\n",
      "Rendering successful episode 15\n",
      "\n",
      "Rendering successful episode 16\n",
      "\n",
      "Rendering successful episode 17\n",
      "\n",
      "Rendering successful episode 18\n",
      "\n",
      "Rendering successful episode 19\n",
      "\n",
      "Rendering successful episode 20\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mRendering successful episode \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;250m \u001b[39m+\u001b[38;5;250m \u001b[39m\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m      3\u001b[39m env = gym.make(\u001b[33m\"\u001b[39m\u001b[33mcustom-intersection-v0\u001b[39m\u001b[33m\"\u001b[39m, render_mode=\u001b[33m'\u001b[39m\u001b[33mhuman\u001b[39m\u001b[33m'\u001b[39m, config=config)\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m obs, _ = \u001b[43menv\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m obs, action \u001b[38;5;129;01min\u001b[39;00m trajectory:\n\u001b[32m      6\u001b[39m     env.step(action)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/cse-190-final-project/.venv/lib/python3.13/site-packages/gymnasium/wrappers/common.py:400\u001b[39m, in \u001b[36mOrderEnforcing.reset\u001b[39m\u001b[34m(self, seed, options)\u001b[39m\n\u001b[32m    398\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Resets the environment with `kwargs`.\"\"\"\u001b[39;00m\n\u001b[32m    399\u001b[39m \u001b[38;5;28mself\u001b[39m._has_reset = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m400\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseed\u001b[49m\u001b[43m=\u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/cse-190-final-project/.venv/lib/python3.13/site-packages/gymnasium/core.py:333\u001b[39m, in \u001b[36mWrapper.reset\u001b[39m\u001b[34m(self, seed, options)\u001b[39m\n\u001b[32m    329\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mreset\u001b[39m(\n\u001b[32m    330\u001b[39m     \u001b[38;5;28mself\u001b[39m, *, seed: \u001b[38;5;28mint\u001b[39m | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m, options: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    331\u001b[39m ) -> \u001b[38;5;28mtuple\u001b[39m[WrapperObsType, \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any]]:\n\u001b[32m    332\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Uses the :meth:`reset` of the :attr:`env` that can be overwritten to change the returned data.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m333\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43menv\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseed\u001b[49m\u001b[43m=\u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/cse-190-final-project/.venv/lib/python3.13/site-packages/gymnasium/wrappers/common.py:293\u001b[39m, in \u001b[36mPassiveEnvChecker.reset\u001b[39m\u001b[34m(self, seed, options)\u001b[39m\n\u001b[32m    291\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.checked_reset \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[32m    292\u001b[39m     \u001b[38;5;28mself\u001b[39m.checked_reset = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m293\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43menv_reset_passive_checker\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m=\u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    294\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    295\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.env.reset(seed=seed, options=options)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/cse-190-final-project/.venv/lib/python3.13/site-packages/gymnasium/utils/passive_env_checker.py:185\u001b[39m, in \u001b[36menv_reset_passive_checker\u001b[39m\u001b[34m(env, **kwargs)\u001b[39m\n\u001b[32m    180\u001b[39m     logger.deprecation(\n\u001b[32m    181\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mCurrent gymnasium version requires that `Env.reset` can be passed `options` to allow the environment initialisation to be passed additional information.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    182\u001b[39m     )\n\u001b[32m    184\u001b[39m \u001b[38;5;66;03m# Checks the result of env.reset with kwargs\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m185\u001b[39m result = \u001b[43menv\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    187\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[32m    188\u001b[39m     logger.warn(\n\u001b[32m    189\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mThe result returned by `env.reset()` was not a tuple of the form `(obs, info)`, where `obs` is a observation and `info` is a dictionary containing additional information. Actual type: `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(result)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m`\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    190\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/cse-190-final-project/.venv/lib/python3.13/site-packages/highway_env/envs/common/abstract.py:208\u001b[39m, in \u001b[36mAbstractEnv.reset\u001b[39m\u001b[34m(self, seed, options)\u001b[39m\n\u001b[32m    206\u001b[39m \u001b[38;5;28mself\u001b[39m.time = \u001b[38;5;28mself\u001b[39m.steps = \u001b[32m0\u001b[39m\n\u001b[32m    207\u001b[39m \u001b[38;5;28mself\u001b[39m.done = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m208\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_reset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    209\u001b[39m \u001b[38;5;28mself\u001b[39m.define_spaces()  \u001b[38;5;66;03m# Second, to link the obs and actions to the vehicles once the scene is created\u001b[39;00m\n\u001b[32m    210\u001b[39m obs = \u001b[38;5;28mself\u001b[39m.observation_type.observe()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/cse-190-final-project/stable_baselines3/intersection_env.py:133\u001b[39m, in \u001b[36mIntersectionEnv._reset\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    131\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_reset\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    132\u001b[39m     \u001b[38;5;28mself\u001b[39m._make_road()\n\u001b[32m--> \u001b[39m\u001b[32m133\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_vehicles\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43minitial_vehicle_count\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/cse-190-final-project/stable_baselines3/custom_intersection_env.py:127\u001b[39m, in \u001b[36mCustomIntersectionEnv._make_vehicles\u001b[39m\u001b[34m(self, n_vehicles)\u001b[39m\n\u001b[32m    122\u001b[39m     \u001b[38;5;28mself\u001b[39m._spawn_vehicle(np.linspace(\u001b[32m0\u001b[39m, \u001b[32m80\u001b[39m, n_vehicles)[t])\n\u001b[32m    123\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(simulation_steps):\n\u001b[32m    124\u001b[39m     [\n\u001b[32m    125\u001b[39m         (\n\u001b[32m    126\u001b[39m             \u001b[38;5;28mself\u001b[39m.road.act(),\n\u001b[32m--> \u001b[39m\u001b[32m127\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mroad\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m/\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msimulation_frequency\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[32m    128\u001b[39m         )\n\u001b[32m    129\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m.config[\u001b[33m\"\u001b[39m\u001b[33msimulation_frequency\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m    130\u001b[39m     ]\n\u001b[32m    132\u001b[39m \u001b[38;5;66;03m# Controlled vehicles\u001b[39;00m\n\u001b[32m    133\u001b[39m \u001b[38;5;28mself\u001b[39m.controlled_vehicles = []\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/cse-190-final-project/.venv/lib/python3.13/site-packages/highway_env/road/regulation.py:32\u001b[39m, in \u001b[36mRegulatedRoad.step\u001b[39m\u001b[34m(self, dt)\u001b[39m\n\u001b[32m     30\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.steps % \u001b[38;5;28mint\u001b[39m(\u001b[32m1\u001b[39m / dt / \u001b[38;5;28mself\u001b[39m.REGULATION_FREQUENCY) == \u001b[32m0\u001b[39m:\n\u001b[32m     31\u001b[39m     \u001b[38;5;28mself\u001b[39m.enforce_road_rules()\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdt\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/cse-190-final-project/.venv/lib/python3.13/site-packages/highway_env/road/road.py:473\u001b[39m, in \u001b[36mRoad.step\u001b[39m\u001b[34m(self, dt)\u001b[39m\n\u001b[32m    467\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    468\u001b[39m \u001b[33;03mStep the dynamics of each entity on the road.\u001b[39;00m\n\u001b[32m    469\u001b[39m \n\u001b[32m    470\u001b[39m \u001b[33;03m:param dt: timestep [s]\u001b[39;00m\n\u001b[32m    471\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    472\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m vehicle \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.vehicles:\n\u001b[32m--> \u001b[39m\u001b[32m473\u001b[39m     \u001b[43mvehicle\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    474\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, vehicle \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m.vehicles):\n\u001b[32m    475\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m other \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.vehicles[i + \u001b[32m1\u001b[39m :]:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/cse-190-final-project/.venv/lib/python3.13/site-packages/highway_env/vehicle/behavior.py:148\u001b[39m, in \u001b[36mIDMVehicle.step\u001b[39m\u001b[34m(self, dt)\u001b[39m\n\u001b[32m    140\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    141\u001b[39m \u001b[33;03mStep the simulation.\u001b[39;00m\n\u001b[32m    142\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    145\u001b[39m \u001b[33;03m:param dt: timestep\u001b[39;00m\n\u001b[32m    146\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    147\u001b[39m \u001b[38;5;28mself\u001b[39m.timer += dt\n\u001b[32m--> \u001b[39m\u001b[32m148\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdt\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/cse-190-final-project/.venv/lib/python3.13/site-packages/highway_env/vehicle/kinematics.py:153\u001b[39m, in \u001b[36mVehicle.step\u001b[39m\u001b[34m(self, dt)\u001b[39m\n\u001b[32m    151\u001b[39m \u001b[38;5;28mself\u001b[39m.heading += \u001b[38;5;28mself\u001b[39m.speed * np.sin(beta) / (\u001b[38;5;28mself\u001b[39m.LENGTH / \u001b[32m2\u001b[39m) * dt\n\u001b[32m    152\u001b[39m \u001b[38;5;28mself\u001b[39m.speed += \u001b[38;5;28mself\u001b[39m.action[\u001b[33m\"\u001b[39m\u001b[33macceleration\u001b[39m\u001b[33m\"\u001b[39m] * dt\n\u001b[32m--> \u001b[39m\u001b[32m153\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mon_state_update\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/cse-190-final-project/.venv/lib/python3.13/site-packages/highway_env/vehicle/kinematics.py:172\u001b[39m, in \u001b[36mVehicle.on_state_update\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    170\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mon_state_update\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    171\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.road:\n\u001b[32m--> \u001b[39m\u001b[32m172\u001b[39m         \u001b[38;5;28mself\u001b[39m.lane_index = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mroad\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnetwork\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_closest_lane_index\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    173\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mposition\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mheading\u001b[49m\n\u001b[32m    174\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    175\u001b[39m         \u001b[38;5;28mself\u001b[39m.lane = \u001b[38;5;28mself\u001b[39m.road.network.get_lane(\u001b[38;5;28mself\u001b[39m.lane_index)\n\u001b[32m    176\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.road.record_history:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/cse-190-final-project/.venv/lib/python3.13/site-packages/highway_env/road/road.py:69\u001b[39m, in \u001b[36mRoadNetwork.get_closest_lane_index\u001b[39m\u001b[34m(self, position, heading)\u001b[39m\n\u001b[32m     67\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m _to, lanes \u001b[38;5;129;01min\u001b[39;00m to_dict.items():\n\u001b[32m     68\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m _id, l \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(lanes):\n\u001b[32m---> \u001b[39m\u001b[32m69\u001b[39m             distances.append(\u001b[43ml\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdistance_with_heading\u001b[49m\u001b[43m(\u001b[49m\u001b[43mposition\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheading\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m     70\u001b[39m             indexes.append((_from, _to, _id))\n\u001b[32m     71\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m indexes[\u001b[38;5;28mint\u001b[39m(np.argmin(distances))]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/cse-190-final-project/.venv/lib/python3.13/site-packages/highway_env/road/lane.py:141\u001b[39m, in \u001b[36mAbstractLane.distance_with_heading\u001b[39m\u001b[34m(self, position, heading, heading_weight)\u001b[39m\n\u001b[32m    139\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m heading \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    140\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.distance(position)\n\u001b[32m--> \u001b[39m\u001b[32m141\u001b[39m s, r = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlocal_coordinates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mposition\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    142\u001b[39m angle = np.abs(\u001b[38;5;28mself\u001b[39m.local_angle(heading, s))\n\u001b[32m    143\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mabs\u001b[39m(r) + \u001b[38;5;28mmax\u001b[39m(s - \u001b[38;5;28mself\u001b[39m.length, \u001b[32m0\u001b[39m) + \u001b[38;5;28mmax\u001b[39m(\u001b[32m0\u001b[39m - s, \u001b[32m0\u001b[39m) + heading_weight * angle\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/cse-190-final-project/.venv/lib/python3.13/site-packages/highway_env/road/lane.py:211\u001b[39m, in \u001b[36mStraightLane.local_coordinates\u001b[39m\u001b[34m(self, position)\u001b[39m\n\u001b[32m    209\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mlocal_coordinates\u001b[39m(\u001b[38;5;28mself\u001b[39m, position: np.ndarray) -> \u001b[38;5;28mtuple\u001b[39m[\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mfloat\u001b[39m]:\n\u001b[32m    210\u001b[39m     delta = position - \u001b[38;5;28mself\u001b[39m.start\n\u001b[32m--> \u001b[39m\u001b[32m211\u001b[39m     longitudinal = \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdelta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdirection\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    212\u001b[39m     lateral = np.dot(delta, \u001b[38;5;28mself\u001b[39m.direction_lateral)\n\u001b[32m    213\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mfloat\u001b[39m(longitudinal), \u001b[38;5;28mfloat\u001b[39m(lateral)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/cse-190-final-project/.venv/lib/python3.13/site-packages/numpy/_core/multiarray.py:761\u001b[39m, in \u001b[36mdot\u001b[39m\u001b[34m(a, b, out)\u001b[39m\n\u001b[32m    692\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    693\u001b[39m \u001b[33;03m    result_type(*arrays_and_dtypes)\u001b[39;00m\n\u001b[32m    694\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    756\u001b[39m \n\u001b[32m    757\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m    758\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m arrays_and_dtypes\n\u001b[32m--> \u001b[39m\u001b[32m761\u001b[39m \u001b[38;5;129m@array_function_from_c_func_and_dispatcher\u001b[39m(_multiarray_umath.dot)\n\u001b[32m    762\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdot\u001b[39m(a, b, out=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m    763\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    764\u001b[39m \u001b[33;03m    dot(a, b, out=None)\u001b[39;00m\n\u001b[32m    765\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    851\u001b[39m \n\u001b[32m    852\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m    853\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m (a, b, out)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "for i, (config, trajectory) in enumerate(successful_runs):\n",
    "    print(f\"\\nRendering successful episode {i + 1}\")\n",
    "    env = gym.make(\"custom-intersection-v0\", render_mode='human', config=config)\n",
    "    obs, _ = env.reset()\n",
    "    for obs, action in trajectory:\n",
    "        env.step(action)\n",
    "        env.render()\n",
    "        time.sleep(0.05)\n",
    "    env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
