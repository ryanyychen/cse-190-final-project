{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "972d8446",
   "metadata": {},
   "source": [
    "# CHANGE THESE CONFIGS, THEN UPDATE MODEL INITIALIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8810a56e",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = \"./models/ppo/ppo\"\n",
    "TENSORBOARD_LOG_DIR = \"./models/ppo/logs\"\n",
    "IMAGE_TAG = \"ppo_rewards\"\n",
    "IMAGE_DIR = \"./images/ppo\"\n",
    "RUNS_FILE = \"./models/ppo/ppo_success_runs.pkl\"\n",
    "\n",
    "#### ENV CONFIGS ####\n",
    "CONFIG = {\n",
    "    \"observation\": {\n",
    "        \"type\": \"Kinematics\",\n",
    "        \"vehicles_count\": 15,\n",
    "        \"features\": [\"presence\", \"x\", \"y\", \"vx\", \"vy\"],\n",
    "        \"features_range\": {\n",
    "            \"x\": [-100, 100],\n",
    "            \"y\": [-100, 100],\n",
    "            \"vx\": [-10, 10],\n",
    "            \"vy\": [-10, 10],\n",
    "        },\n",
    "        \"absolute\": False,\n",
    "        \"clip\": False,\n",
    "        \"normalize\": False,\n",
    "    },\n",
    "    # ─────────────── Switch to continuous actions ───────────────\n",
    "    \"action\": {\n",
    "        \"type\": \"ContinuousAction\",\n",
    "    },\n",
    "    # ───────────────────────── Other settings ─────────────────────────\n",
    "    \"duration\": 15,\n",
    "    \"simulation_frequency\": 10,\n",
    "    \"policy_frequency\": 10,\n",
    "    \"destination\": \"o1\",\n",
    "    \"initial_vehicle_count\": 20,\n",
    "    \"spawn_probability\": 0.8,\n",
    "    \"ego_spacing\": 25,\n",
    "    \"initial_lane_id\": None,\n",
    "    \"controlled_vehicles\": 1,\n",
    "    \"duration\": 15,\n",
    "    \"vehicles_density\": 1.0,\n",
    "    \"screen_width\": 600,\n",
    "    \"screen_height\": 600,\n",
    "    \"centering_position\": [0.5, 0.6],\n",
    "    \"scaling\": 5.5 * 1.3,\n",
    "    \"normalize_reward\": False,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3698ca84",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5b59c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "import pickle\n",
    "import random\n",
    "import gymnasium as gym\n",
    "\n",
    "from fvcore.nn import FlopCountAnalysis\n",
    "\n",
    "from stable_baselines3 import A2C, PPO, SAC\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3.common.callbacks import ProgressBarCallback\n",
    "\n",
    "from custom_intersection_env import CustomIntersectionEnv\n",
    "from simple_intersection_env import SimpleIntersectionEnv\n",
    "from custom_training_callback import RewardTrackingCallback"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33468fde",
   "metadata": {},
   "source": [
    "## Register Env with Gymnasium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "01a76e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "gym.envs.registration.register(\n",
    "    id=\"simple-intersection-v0\",\n",
    "    entry_point=\"simple_intersection_env:SimpleIntersectionEnv\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea952aa",
   "metadata": {},
   "source": [
    "## Create and Wrap Env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc8a4fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"simple-intersection-v0\", render_mode='rgb_array', config=CONFIG)\n",
    "env = DummyVecEnv([lambda: env])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d79e0f",
   "metadata": {},
   "source": [
    "## UPDATE HERE: Set Up Correct Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a151beac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Projects\\CSE190\\cse-190-final-project\\venv\\Lib\\site-packages\\stable_baselines3\\ppo\\ppo.py:155: UserWarning: You have specified a mini-batch size of 64, but because the `RolloutBuffer` is of size `n_steps * n_envs = 1000`, after every 15 untruncated mini-batches, there will be a truncated mini-batch of size 40\n",
      "We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.\n",
      "Info: (n_steps=1000 and n_envs=1)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = PPO(\n",
    "    policy=\"MlpPolicy\",\n",
    "    env=env,\n",
    "    learning_rate=3e-4,\n",
    "    n_steps=1000,           # on‐policy rollout length\n",
    "    batch_size=64,\n",
    "    n_epochs=10,\n",
    "    gamma=0.95,\n",
    "    gae_lambda=0.95,\n",
    "    clip_range=0.2,\n",
    "    ent_coef=0.01,\n",
    "    vf_coef=0.5,\n",
    "    max_grad_norm=0.5,\n",
    "    use_sde=False,          # you can set True for state‐dependent noise\n",
    "    sde_sample_freq=-1,\n",
    "    tensorboard_log=\"./ppo_cont_tb/\",\n",
    "    verbose=0,\n",
    "    device=\"cpu\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e86ccb7b",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "030f8276",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f52048ba56f34cbbb105e117bc291f7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "reward_callback = RewardTrackingCallback(\n",
    "    tag=IMAGE_TAG,\n",
    "    path_dir=IMAGE_DIR\n",
    ")\n",
    "\n",
    "destinations = [\"o1\", \"o2\", \"o3\"]\n",
    "steps = [250000 for _ in destinations]\n",
    "\n",
    "for dest, steps in zip(destinations, steps):\n",
    "    config = CONFIG.copy()\n",
    "    config[\"destination\"] = dest  # Change destination for each training phase\n",
    "    env = gym.make(\"simple-intersection-v0\", render_mode='rgb_array', config=config)\n",
    "    env = DummyVecEnv([lambda: env])\n",
    "    model.set_env(env)  # Update the model with the new environment\n",
    "    model.learn(\n",
    "        total_timesteps=steps,\n",
    "        callback=[ProgressBarCallback(), reward_callback]\n",
    "    )\n",
    "    reward_callback.start_new_phase()\n",
    "reward_callback.save_all_plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d85c4906",
   "metadata": {},
   "source": [
    "### Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f66b96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(MODEL_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "578176a8",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "956c1302",
   "metadata": {},
   "source": [
    "### Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2030a4d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Projects\\CSE190\\cse-190-final-project\\venv\\Lib\\site-packages\\stable_baselines3\\common\\on_policy_algorithm.py:150: UserWarning: You are trying to run PPO on the GPU, but it is primarily intended to run on the CPU when not using a CNN policy (you are using ActorCriticPolicy which should be a MlpPolicy). See https://github.com/DLR-RM/stable-baselines3/issues/1245 for more info. You can pass `device='cpu'` or `export CUDA_VISIBLE_DEVICES=` to force using the CPU.Note: The model will train, but the GPU utilization will be poor and the training might take longer than on CPU.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = PPO.load(MODEL_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72cb9ebe",
   "metadata": {},
   "source": [
    "### Run Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eeefa53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1 finished, total reward: 21.0, destination: o1, arrived: True, crashed: False\n",
      "Episode 2 finished, total reward: -20.0, destination: o2, arrived: False, crashed: True\n",
      "Episode 3 finished, total reward: 164.0, destination: o2, arrived: False, crashed: False\n",
      "Episode 4 finished, total reward: -21.0, destination: o2, arrived: False, crashed: True\n",
      "Episode 5 finished, total reward: -8.0, destination: o2, arrived: False, crashed: True\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 39\u001b[39m\n\u001b[32m     37\u001b[39m     action, _states = model.predict(obs, deterministic=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     38\u001b[39m     trajectory.append((obs, action))\n\u001b[32m---> \u001b[39m\u001b[32m39\u001b[39m     obs, reward, done, truncated, info = \u001b[43menv\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     40\u001b[39m     episode_reward += reward\n\u001b[32m     42\u001b[39m crashed = info.get(\u001b[33m\"\u001b[39m\u001b[33mcrashed\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Projects\\CSE190\\cse-190-final-project\\venv\\Lib\\site-packages\\gymnasium\\wrappers\\common.py:393\u001b[39m, in \u001b[36mOrderEnforcing.step\u001b[39m\u001b[34m(self, action)\u001b[39m\n\u001b[32m    391\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._has_reset:\n\u001b[32m    392\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m ResetNeeded(\u001b[33m\"\u001b[39m\u001b[33mCannot call env.step() before calling env.reset()\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m393\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Projects\\CSE190\\cse-190-final-project\\venv\\Lib\\site-packages\\gymnasium\\core.py:327\u001b[39m, in \u001b[36mWrapper.step\u001b[39m\u001b[34m(self, action)\u001b[39m\n\u001b[32m    323\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mstep\u001b[39m(\n\u001b[32m    324\u001b[39m     \u001b[38;5;28mself\u001b[39m, action: WrapperActType\n\u001b[32m    325\u001b[39m ) -> \u001b[38;5;28mtuple\u001b[39m[WrapperObsType, SupportsFloat, \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any]]:\n\u001b[32m    326\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Uses the :meth:`step` of the :attr:`env` that can be overwritten to change the returned data.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m327\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43menv\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Projects\\CSE190\\cse-190-final-project\\venv\\Lib\\site-packages\\gymnasium\\wrappers\\common.py:285\u001b[39m, in \u001b[36mPassiveEnvChecker.step\u001b[39m\u001b[34m(self, action)\u001b[39m\n\u001b[32m    283\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m env_step_passive_checker(\u001b[38;5;28mself\u001b[39m.env, action)\n\u001b[32m    284\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m285\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43menv\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Projects\\CSE190\\cse-190-final-project\\stable_baselines3\\custom_intersection_env.py:33\u001b[39m, in \u001b[36mCustomIntersectionEnv.step\u001b[39m\u001b[34m(self, action)\u001b[39m\n\u001b[32m     26\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mstep\u001b[39m(\u001b[38;5;28mself\u001b[39m, action):\n\u001b[32m     27\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     28\u001b[39m \u001b[33;03m    1) Call parent class to advance the simulation.\u001b[39;00m\n\u001b[32m     29\u001b[39m \u001b[33;03m    2) Check for dangerously close vehicles (distance < min_safe_distance).\u001b[39;00m\n\u001b[32m     30\u001b[39m \u001b[33;03m        If so, assign a large negative reward and terminate immediately.\u001b[39;00m\n\u001b[32m     31\u001b[39m \u001b[33;03m    3) Otherwise, compute our custom reward with _reward(action).\u001b[39;00m\n\u001b[32m     32\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m33\u001b[39m     obs, _, done, truncated, \u001b[38;5;28mself\u001b[39m.info = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     34\u001b[39m     \u001b[38;5;28mself\u001b[39m.steps += \u001b[32m1\u001b[39m\n\u001b[32m     35\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.steps >= \u001b[38;5;28mself\u001b[39m._max_steps \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m done:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Projects\\CSE190\\cse-190-final-project\\stable_baselines3\\intersection_env.py:136\u001b[39m, in \u001b[36mIntersectionEnv.step\u001b[39m\u001b[34m(self, action)\u001b[39m\n\u001b[32m    135\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mstep\u001b[39m(\u001b[38;5;28mself\u001b[39m, action: \u001b[38;5;28mint\u001b[39m) -> \u001b[38;5;28mtuple\u001b[39m[np.ndarray, \u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mdict\u001b[39m]:\n\u001b[32m--> \u001b[39m\u001b[32m136\u001b[39m     obs, reward, terminated, truncated, info = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    137\u001b[39m     \u001b[38;5;28mself\u001b[39m._clear_vehicles()\n\u001b[32m    138\u001b[39m     \u001b[38;5;28mself\u001b[39m._spawn_vehicle(spawn_probability=\u001b[38;5;28mself\u001b[39m.config[\u001b[33m\"\u001b[39m\u001b[33mspawn_probability\u001b[39m\u001b[33m\"\u001b[39m])\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Projects\\CSE190\\cse-190-final-project\\venv\\Lib\\site-packages\\highway_env\\envs\\common\\abstract.py:240\u001b[39m, in \u001b[36mAbstractEnv.step\u001b[39m\u001b[34m(self, action)\u001b[39m\n\u001b[32m    235\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[32m    236\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mThe road and vehicle must be initialized in the environment implementation\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    237\u001b[39m     )\n\u001b[32m    239\u001b[39m \u001b[38;5;28mself\u001b[39m.time += \u001b[32m1\u001b[39m / \u001b[38;5;28mself\u001b[39m.config[\u001b[33m\"\u001b[39m\u001b[33mpolicy_frequency\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m--> \u001b[39m\u001b[32m240\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_simulate\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    242\u001b[39m obs = \u001b[38;5;28mself\u001b[39m.observation_type.observe()\n\u001b[32m    243\u001b[39m reward = \u001b[38;5;28mself\u001b[39m._reward(action)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Projects\\CSE190\\cse-190-final-project\\venv\\Lib\\site-packages\\highway_env\\envs\\common\\abstract.py:272\u001b[39m, in \u001b[36mAbstractEnv._simulate\u001b[39m\u001b[34m(self, action)\u001b[39m\n\u001b[32m    269\u001b[39m     \u001b[38;5;28mself\u001b[39m.action_type.act(action)\n\u001b[32m    271\u001b[39m \u001b[38;5;28mself\u001b[39m.road.act()\n\u001b[32m--> \u001b[39m\u001b[32m272\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mroad\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m/\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msimulation_frequency\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    273\u001b[39m \u001b[38;5;28mself\u001b[39m.steps += \u001b[32m1\u001b[39m\n\u001b[32m    275\u001b[39m \u001b[38;5;66;03m# Automatically render intermediate simulation steps if a viewer has been launched\u001b[39;00m\n\u001b[32m    276\u001b[39m \u001b[38;5;66;03m# Ignored if the rendering is done offscreen\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Projects\\CSE190\\cse-190-final-project\\venv\\Lib\\site-packages\\highway_env\\road\\regulation.py:32\u001b[39m, in \u001b[36mRegulatedRoad.step\u001b[39m\u001b[34m(self, dt)\u001b[39m\n\u001b[32m     30\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.steps % \u001b[38;5;28mint\u001b[39m(\u001b[32m1\u001b[39m / dt / \u001b[38;5;28mself\u001b[39m.REGULATION_FREQUENCY) == \u001b[32m0\u001b[39m:\n\u001b[32m     31\u001b[39m     \u001b[38;5;28mself\u001b[39m.enforce_road_rules()\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdt\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Projects\\CSE190\\cse-190-final-project\\venv\\Lib\\site-packages\\highway_env\\road\\road.py:473\u001b[39m, in \u001b[36mRoad.step\u001b[39m\u001b[34m(self, dt)\u001b[39m\n\u001b[32m    467\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    468\u001b[39m \u001b[33;03mStep the dynamics of each entity on the road.\u001b[39;00m\n\u001b[32m    469\u001b[39m \n\u001b[32m    470\u001b[39m \u001b[33;03m:param dt: timestep [s]\u001b[39;00m\n\u001b[32m    471\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    472\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m vehicle \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.vehicles:\n\u001b[32m--> \u001b[39m\u001b[32m473\u001b[39m     \u001b[43mvehicle\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    474\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, vehicle \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m.vehicles):\n\u001b[32m    475\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m other \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.vehicles[i + \u001b[32m1\u001b[39m :]:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Projects\\CSE190\\cse-190-final-project\\venv\\Lib\\site-packages\\highway_env\\vehicle\\behavior.py:148\u001b[39m, in \u001b[36mIDMVehicle.step\u001b[39m\u001b[34m(self, dt)\u001b[39m\n\u001b[32m    140\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    141\u001b[39m \u001b[33;03mStep the simulation.\u001b[39;00m\n\u001b[32m    142\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    145\u001b[39m \u001b[33;03m:param dt: timestep\u001b[39;00m\n\u001b[32m    146\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    147\u001b[39m \u001b[38;5;28mself\u001b[39m.timer += dt\n\u001b[32m--> \u001b[39m\u001b[32m148\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdt\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Projects\\CSE190\\cse-190-final-project\\venv\\Lib\\site-packages\\highway_env\\vehicle\\kinematics.py:153\u001b[39m, in \u001b[36mVehicle.step\u001b[39m\u001b[34m(self, dt)\u001b[39m\n\u001b[32m    151\u001b[39m \u001b[38;5;28mself\u001b[39m.heading += \u001b[38;5;28mself\u001b[39m.speed * np.sin(beta) / (\u001b[38;5;28mself\u001b[39m.LENGTH / \u001b[32m2\u001b[39m) * dt\n\u001b[32m    152\u001b[39m \u001b[38;5;28mself\u001b[39m.speed += \u001b[38;5;28mself\u001b[39m.action[\u001b[33m\"\u001b[39m\u001b[33macceleration\u001b[39m\u001b[33m\"\u001b[39m] * dt\n\u001b[32m--> \u001b[39m\u001b[32m153\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mon_state_update\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Projects\\CSE190\\cse-190-final-project\\venv\\Lib\\site-packages\\highway_env\\vehicle\\kinematics.py:172\u001b[39m, in \u001b[36mVehicle.on_state_update\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    170\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mon_state_update\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    171\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.road:\n\u001b[32m--> \u001b[39m\u001b[32m172\u001b[39m         \u001b[38;5;28mself\u001b[39m.lane_index = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mroad\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnetwork\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_closest_lane_index\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    173\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mposition\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mheading\u001b[49m\n\u001b[32m    174\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    175\u001b[39m         \u001b[38;5;28mself\u001b[39m.lane = \u001b[38;5;28mself\u001b[39m.road.network.get_lane(\u001b[38;5;28mself\u001b[39m.lane_index)\n\u001b[32m    176\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.road.record_history:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Projects\\CSE190\\cse-190-final-project\\venv\\Lib\\site-packages\\highway_env\\road\\road.py:69\u001b[39m, in \u001b[36mRoadNetwork.get_closest_lane_index\u001b[39m\u001b[34m(self, position, heading)\u001b[39m\n\u001b[32m     67\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m _to, lanes \u001b[38;5;129;01min\u001b[39;00m to_dict.items():\n\u001b[32m     68\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m _id, l \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(lanes):\n\u001b[32m---> \u001b[39m\u001b[32m69\u001b[39m             distances.append(\u001b[43ml\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdistance_with_heading\u001b[49m\u001b[43m(\u001b[49m\u001b[43mposition\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheading\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m     70\u001b[39m             indexes.append((_from, _to, _id))\n\u001b[32m     71\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m indexes[\u001b[38;5;28mint\u001b[39m(np.argmin(distances))]\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Projects\\CSE190\\cse-190-final-project\\venv\\Lib\\site-packages\\highway_env\\road\\lane.py:141\u001b[39m, in \u001b[36mAbstractLane.distance_with_heading\u001b[39m\u001b[34m(self, position, heading, heading_weight)\u001b[39m\n\u001b[32m    139\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m heading \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    140\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.distance(position)\n\u001b[32m--> \u001b[39m\u001b[32m141\u001b[39m s, r = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlocal_coordinates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mposition\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    142\u001b[39m angle = np.abs(\u001b[38;5;28mself\u001b[39m.local_angle(heading, s))\n\u001b[32m    143\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mabs\u001b[39m(r) + \u001b[38;5;28mmax\u001b[39m(s - \u001b[38;5;28mself\u001b[39m.length, \u001b[32m0\u001b[39m) + \u001b[38;5;28mmax\u001b[39m(\u001b[32m0\u001b[39m - s, \u001b[32m0\u001b[39m) + heading_weight * angle\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Projects\\CSE190\\cse-190-final-project\\venv\\Lib\\site-packages\\highway_env\\road\\lane.py:211\u001b[39m, in \u001b[36mStraightLane.local_coordinates\u001b[39m\u001b[34m(self, position)\u001b[39m\n\u001b[32m    209\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mlocal_coordinates\u001b[39m(\u001b[38;5;28mself\u001b[39m, position: np.ndarray) -> \u001b[38;5;28mtuple\u001b[39m[\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mfloat\u001b[39m]:\n\u001b[32m    210\u001b[39m     delta = position - \u001b[38;5;28mself\u001b[39m.start\n\u001b[32m--> \u001b[39m\u001b[32m211\u001b[39m     longitudinal = \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdelta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdirection\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    212\u001b[39m     lateral = np.dot(delta, \u001b[38;5;28mself\u001b[39m.direction_lateral)\n\u001b[32m    213\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mfloat\u001b[39m(longitudinal), \u001b[38;5;28mfloat\u001b[39m(lateral)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import contextlib, io\n",
    "\n",
    "collisions = 0\n",
    "destination_arrivals = 0\n",
    "success_count = 0\n",
    "successful_flopcount = 0\n",
    "episodes = 100\n",
    "\n",
    "# Store successful runs for rendering\n",
    "successful_runs = []\n",
    "\n",
    "for eps in range(100):\n",
    "    config = CONFIG.copy()\n",
    "    config[\"destination\"] = \"o\" + str(random.randint(1, 3))\n",
    "    env = gym.make(\"simple-intersection-v0\", render_mode='rgb_array', config=config)\n",
    "\n",
    "    seed = random.randint(0, 10000)\n",
    "\n",
    "    obs, _ = env.reset(seed=seed)\n",
    "    episode_flops = 0\n",
    "    done = False\n",
    "    truncated = False\n",
    "    episode_reward = 0\n",
    "    trajectory = []\n",
    "\n",
    "    while not (done or truncated):\n",
    "        # === FLOP COUNTING (silenced) ===\n",
    "        f = io.StringIO()\n",
    "        with contextlib.redirect_stdout(f), contextlib.redirect_stderr(f):\n",
    "            # Anything printed by FlopCountAnalysis—whether “unused submodules” or other messages—goes into `f`\n",
    "            input_tensor, _ = model.policy.obs_to_tensor(obs)\n",
    "            flops = FlopCountAnalysis(model.policy, input_tensor)\n",
    "            flops.unsupported_ops_warnings(False)\n",
    "            flops = flops.total()\n",
    "        \n",
    "        episode_flops += flops\n",
    "        action, _states = model.predict(obs, deterministic=True)\n",
    "        trajectory.append((obs, action))\n",
    "        obs, reward, done, truncated, info = env.step(action)\n",
    "        episode_reward += reward\n",
    "    \n",
    "    crashed = info.get(\"crashed\", False)\n",
    "    arrived = info.get(\"arrived\", False)\n",
    "    if crashed:\n",
    "        collisions += 1\n",
    "    if arrived:\n",
    "        destination_arrivals += 1\n",
    "    if (not crashed) and arrived:\n",
    "        success_count += 1\n",
    "        successful_flopcount += episode_flops\n",
    "        successful_runs.append((seed, config.copy(), trajectory))\n",
    "\n",
    "    print(f\"Episode {eps + 1} finished, total reward: {episode_reward}, destination: {config['destination']}, arrived: {arrived}, crashed: {crashed}\")\n",
    "    time.sleep(1)\n",
    "\n",
    "print(f\"Total collisions: {collisions} out of {episodes} episodes\")\n",
    "print(f\"Total destination arrivals: {destination_arrivals} out of {episodes} episodes\")\n",
    "if success_count > 0:\n",
    "    print(f\"FLOPS per successful episode: {successful_flopcount / success_count:.2}\")\n",
    "else:\n",
    "    print(\"No successful episodes.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a66284c6",
   "metadata": {},
   "source": [
    "### Save Successful Runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c84cf3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(RUNS_FILE, \"wb\") as f:\n",
    "    pickle.dump(successful_runs, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b783f032",
   "metadata": {},
   "source": [
    "### Load Successful Runs File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "66f3e3a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(RUNS_FILE, \"rb\") as f:\n",
    "    successful_runs = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70751916",
   "metadata": {},
   "source": [
    "### Render Successful Episodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc716d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Rendering successful episode 1\n",
      "\n",
      "Rendering successful episode 2\n",
      "\n",
      "Rendering successful episode 3\n",
      "\n",
      "Rendering successful episode 4\n",
      "\n",
      "Rendering successful episode 5\n",
      "\n",
      "Rendering successful episode 6\n",
      "\n",
      "Rendering successful episode 7\n",
      "\n",
      "Rendering successful episode 8\n",
      "\n",
      "Rendering successful episode 9\n",
      "\n",
      "Rendering successful episode 10\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      6\u001b[39m     env.step(action)\n\u001b[32m      7\u001b[39m     env.render()\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m     \u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0.05\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      9\u001b[39m env.close()\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "for i, (seed, config, trajectory) in enumerate(successful_runs[20:]):\n",
    "    print(f\"\\nRendering successful episode {i + 1}\")\n",
    "    env = gym.make(\"custom-intersection-v0\", render_mode='human', config=config)\n",
    "    obs, _ = env.reset(seed=seed)\n",
    "    for obs, action in trajectory:\n",
    "        env.step(action)\n",
    "        env.render()\n",
    "        time.sleep(0.05)\n",
    "    env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
