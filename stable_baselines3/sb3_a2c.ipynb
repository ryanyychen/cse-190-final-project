{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "972d8446",
   "metadata": {},
   "source": [
    "# CHANGE THESE CONFIGS, THEN UPDATE MODEL INITIALIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8810a56e",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = \"./models/a2c/a2c\"\n",
    "TENSORBOARD_LOG_DIR = \"./models/a2c/logs\"\n",
    "IMAGE_TAG = \"a2c_rewards\"\n",
    "IMAGE_DIR = \"./images/a2c\"\n",
    "RUNS_FILE = \"./models/a2c/a2c_success_runs.pkl\"\n",
    "\n",
    "#### ENV CONFIGS ####\n",
    "CONFIG = {\n",
    "    \"observation\": {\n",
    "        \"type\": \"Kinematics\",\n",
    "        \"vehicles_count\": 15,  # Number of other vehicles to observe\n",
    "        \"features\": [\"presence\", \"x\", \"y\", \"vx\", \"vy\"],  # Observe position and velocity\n",
    "        \"features_range\": {\n",
    "            \"x\": [-100, 100],\n",
    "            \"y\": [-100, 100],\n",
    "            \"vx\": [-10, 10],\n",
    "            \"vy\": [-10, 10]\n",
    "        },\n",
    "        \"absolute\": False,\n",
    "        \"clip\": False,\n",
    "        \"normalize\": False\n",
    "    },\n",
    "    \"action\": {\n",
    "        \"type\": \"DiscreteMetaAction\",  # Keep simple, 5 discrete actions\n",
    "    },\n",
    "    \"simulation_frequency\": 10,\n",
    "    \"policy_frequency\": 10,\n",
    "    \"destination\": \"o1\",\n",
    "    \"initial_vehicle_count\": 20,\n",
    "    \"spawn_probability\": 0.8,\n",
    "    \"ego_spacing\": 25,\n",
    "    \"initial_lane_id\": None,\n",
    "    \"controlled_vehicles\": 1,\n",
    "    \"duration\": 15,  # seconds\n",
    "    \"vehicles_density\": 1.0,\n",
    "    \"screen_width\": 600,\n",
    "    \"screen_height\": 600,\n",
    "    \"centering_position\": [0.5, 0.6],\n",
    "    \"scaling\": 5.5 * 1.3,\n",
    "    \"normalize_reward\": False\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3698ca84",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5b59c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "import pickle\n",
    "import random\n",
    "import gymnasium as gym\n",
    "\n",
    "from fvcore.nn import FlopCountAnalysis\n",
    "\n",
    "from stable_baselines3 import A2C, PPO, SAC\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3.common.callbacks import ProgressBarCallback\n",
    "\n",
    "from custom_intersection_env import CustomIntersectionEnv\n",
    "from custom_training_callback import RewardTrackingCallback"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33468fde",
   "metadata": {},
   "source": [
    "## Register Env with Gymnasium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01a76e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "gym.envs.registration.register(\n",
    "    id='custom-intersection-v0',\n",
    "    entry_point='custom_intersection_env:CustomIntersectionEnv',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea952aa",
   "metadata": {},
   "source": [
    "## Create and Wrap Env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc8a4fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"custom-intersection-v0\", render_mode='rgb_array', config=CONFIG)\n",
    "env = DummyVecEnv([lambda: env])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d79e0f",
   "metadata": {},
   "source": [
    "## UPDATE HERE: Set Up Correct Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a151beac",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = A2C(\n",
    "    \"MlpPolicy\",\n",
    "    env,\n",
    "    n_steps=5,\n",
    "    learning_rate=7e-4,\n",
    "    gamma=0.99,\n",
    "    gae_lambda=1.0,\n",
    "    ent_coef=0.01,\n",
    "    vf_coef=0.5,\n",
    "    max_grad_norm=0.5,\n",
    "    rms_prop_eps=1e-5,\n",
    "    use_rms_prop=True,\n",
    "    normalize_advantage=False,\n",
    "    tensorboard_log=TENSORBOARD_LOG_DIR,\n",
    "    verbose=0,\n",
    "    device='cpu'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e86ccb7b",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "030f8276",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1d049a9644543d2bfadf6a0976e9ed1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AttributeError",
     "evalue": "'RewardTrackingCallback' object has no attribute 'start_new_phase'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 19\u001b[39m\n\u001b[32m     14\u001b[39m model.set_env(env)  \u001b[38;5;66;03m# Update the model with the new environment\u001b[39;00m\n\u001b[32m     15\u001b[39m model.learn(\n\u001b[32m     16\u001b[39m     total_timesteps=\u001b[32m300000\u001b[39m,\n\u001b[32m     17\u001b[39m     callback=[ProgressBarCallback(), reward_callback]\n\u001b[32m     18\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m \u001b[43mreward_callback\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstart_new_phase\u001b[49m()\n\u001b[32m     20\u001b[39m reward_callback.save_all_plot()\n",
      "\u001b[31mAttributeError\u001b[39m: 'RewardTrackingCallback' object has no attribute 'start_new_phase'"
     ]
    }
   ],
   "source": [
    "reward_callback = RewardTrackingCallback(\n",
    "    tag=IMAGE_TAG,\n",
    "    path_dir=IMAGE_DIR\n",
    ")\n",
    "\n",
    "class DestinationWrapper(gym.Wrapper):\n",
    "    def reset(self, **kwargs):\n",
    "        self.unwrapped.config[\"destination\"] = \"o\" + str(random.randint(1, 3))\n",
    "        return self.env.reset(**kwargs)\n",
    "\n",
    "env = gym.make(\"custom-intersection-v0\", render_mode='rgb_array', config=CONFIG)\n",
    "env = DestinationWrapper(env)\n",
    "env = DummyVecEnv([lambda: env])\n",
    "model.set_env(env)  # Update the model with the new environment\n",
    "model.learn(\n",
    "    total_timesteps=300000,\n",
    "    callback=[ProgressBarCallback(), reward_callback]\n",
    ")\n",
    "reward_callback.save_all_plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d85c4906",
   "metadata": {},
   "source": [
    "### Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f66b96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(MODEL_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "578176a8",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "956c1302",
   "metadata": {},
   "source": [
    "### Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2030a4d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = A2C.load(MODEL_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72cb9ebe",
   "metadata": {},
   "source": [
    "### Run Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eeefa53",
   "metadata": {},
   "outputs": [],
   "source": [
    "collisions = 0\n",
    "destination_arrivals = 0\n",
    "success_count = 0\n",
    "successful_flopcount = 0\n",
    "episodes = 100\n",
    "\n",
    "# Store successful runs for rendering\n",
    "successful_runs = []\n",
    "\n",
    "for eps in range(100):\n",
    "    config = CONFIG.copy()\n",
    "    config[\"destination\"] = \"o\" + str(random.randint(1, 3))\n",
    "    env = gym.make(\"custom-intersection-v0\", render_mode='rgb_array', config=config)\n",
    "\n",
    "    seed = random.randint(0, 10000)\n",
    "\n",
    "    obs, _ = env.reset(seed=seed)\n",
    "    episode_flops = 0\n",
    "    done = False\n",
    "    truncated = False\n",
    "    episode_reward = 0\n",
    "    trajectory = []\n",
    "\n",
    "    while not (done or truncated):\n",
    "        # Flop Counting\n",
    "        input_tensor, _ = model.policy.obs_to_tensor(obs)\n",
    "        flops = FlopCountAnalysis(model.policy, input_tensor)\n",
    "        flops.unsupported_ops_warnings(False)\n",
    "        flops = flops.total()\n",
    "        episode_flops += flops\n",
    "\n",
    "        action, _states = model.predict(obs, deterministic=True)\n",
    "        trajectory.append((obs, action))  # Save for later render if successful\n",
    "        obs, reward, done, truncated, info = env.step(action)\n",
    "        episode_reward += reward\n",
    "    \n",
    "    crashed = info.get(\"crashed\", False)\n",
    "    arrived = info.get(\"arrived\", False)\n",
    "    if crashed:\n",
    "        collisions += 1\n",
    "    if arrived:\n",
    "        destination_arrivals += 1\n",
    "    if (not crashed) and arrived:\n",
    "        success_count += 1\n",
    "        successful_flopcount += episode_flops\n",
    "        successful_runs.append((seed, config.copy(), trajectory))\n",
    "\n",
    "    print(f\"Episode {eps + 1} finished, total reward: {episode_reward}, destination: {config['destination']}\")\n",
    "    time.sleep(1)\n",
    "\n",
    "print(f\"Total collisions: {collisions} out of {episodes} episodes\")\n",
    "print(f\"Total destination arrivals: {destination_arrivals} out of {episodes} episodes\")\n",
    "if success_count > 0:\n",
    "    print(f\"FLOPS per successful episode: {successful_flopcount / success_count:.2}\")\n",
    "else:\n",
    "    print(\"No successful episodes.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a66284c6",
   "metadata": {},
   "source": [
    "### Save Successful Runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c84cf3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(RUNS_FILE, \"wb\") as f:\n",
    "    pickle.dump(successful_runs, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b783f032",
   "metadata": {},
   "source": [
    "### Load Successful Runs File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f3e3a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(RUNS_FILE, \"rb\") as f:\n",
    "    successful_runs = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70751916",
   "metadata": {},
   "source": [
    "### Render Successful Episodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc716d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (seed, config, trajectory) in enumerate(successful_runs):\n",
    "    print(f\"\\nRendering successful episode {i + 1}\")\n",
    "    env = gym.make(\"custom-intersection-v0\", render_mode='human', config=config)\n",
    "    obs, _ = env.reset(seed=seed)\n",
    "    for obs, action in trajectory:\n",
    "        env.step(action)\n",
    "        env.render()\n",
    "        time.sleep(0.05)\n",
    "    env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
