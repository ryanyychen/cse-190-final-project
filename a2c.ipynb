{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86dda4c5",
   "metadata": {},
   "source": [
    "# A2C (Advantage Actor-Critic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf68b89c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\igor\\Documents\\UCSD\\CSE190_Ammanbdrolu\\cse-190-final-project\\.venv\\Lib\\site-packages\\pygame\\pkgdata.py:25: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import resource_stream, resource_exists\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment configuration:\n",
      "observation: {'type': 'Kinematics', 'vehicles_count': 10, 'features': ['presence', 'x', 'y', 'vx', 'vy', 'cos_h', 'sin_h'], 'features_range': {'x': [-100, 100], 'y': [-100, 100], 'vx': [-20, 20], 'vy': [-20, 20]}, 'absolute': False, 'sorted': True}\n",
      "action: {'type': 'ContinuousAction'}\n",
      "simulation_frequency: 15\n",
      "policy_frequency: 2\n",
      "other_vehicles_type: highway_env.vehicle.behavior.IDMVehicle\n",
      "screen_width: 600\n",
      "screen_height: 600\n",
      "centering_position: [0.5, 0.6]\n",
      "scaling: 7.15\n",
      "show_trajectories: False\n",
      "render_agent: True\n",
      "offscreen_rendering: False\n",
      "manual_control: False\n",
      "real_time_rendering: False\n",
      "duration: 50\n",
      "destination: o1\n",
      "controlled_vehicles: 1\n",
      "initial_vehicle_count: 10\n",
      "spawn_probability: 0.6\n",
      "collision_reward: -100.0\n",
      "high_speed_reward: 0.0\n",
      "arrived_reward: 50.0\n",
      "reward_speed_range: [0.0, 3.0]\n",
      "normalize_reward: False\n",
      "offroad_terminal: True\n",
      "vehicle: {'acceleration': 3.0, 'steering': 0.4}\n",
      "collision_terminal: True\n",
      "Model configuration:\n",
      "{'hidden_size': 128, 'learning_rate': 0.005, 'gamma': 0.95, 'num_episodes_train': 3000, 'print_freq': 100, 'save_freq': 1000, 'num_episodes_eval': 100, 'top_k': 5}\n",
      "State size: 70, Action size: 2\n",
      "Model loaded from ./models/a2c.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating A2C Agent: 100%|██████████| 100/100 [00:35<00:00,  2.86it/s]\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "### One-cell script to run evaluation\n",
    "import yaml\n",
    "import numpy as np\n",
    "from env import create_env\n",
    "from algorithms.a2c import A2CAgent\n",
    "\n",
    "SEED = 42\n",
    "ENV_CONFIG = './configs/env.yaml'\n",
    "MODEL_CONFIG = './configs/a2c.yaml'\n",
    "# MODEL_PATH = './models/a2c_ep1000.pth'\n",
    "MODEL_PATH = './models/a2c.pth'\n",
    "\n",
    "eval_env = create_env(\n",
    "    config_filepath=ENV_CONFIG,\n",
    "    render_mode='rgb_array',\n",
    ")\n",
    "eval_env.reset(seed=SEED)\n",
    "\n",
    "# Display env configs\n",
    "print(\"Environment configuration:\")\n",
    "for key in eval_env.config.keys():\n",
    "    print(f'{key}: {eval_env.config[key]}')\n",
    "\n",
    "with open(MODEL_CONFIG, 'r') as file:\n",
    "    config = yaml.safe_load(file)\n",
    "    print(\"Model configuration:\")\n",
    "    print(config)\n",
    "\n",
    "state_size = np.prod(eval_env.observation_space.shape)\n",
    "action_size = eval_env.action_space.shape[0]\n",
    "print(f\"State size: {state_size}, Action size: {action_size}\")\n",
    "agent = A2CAgent(\n",
    "    state_size=state_size,\n",
    "    hidden_size=config['hidden_size'],\n",
    "    action_size=action_size,\n",
    "    learning_rate=config['learning_rate'],\n",
    "    gamma=config['gamma'],\n",
    "    model_path=MODEL_PATH,\n",
    ")\n",
    "\n",
    "agent.load_model(\n",
    "    model_path=MODEL_PATH,\n",
    ")\n",
    "\n",
    "agent.evaluate(\n",
    "    env=eval_env,\n",
    "    num_episodes=config['num_episodes_eval'],\n",
    "    top_k=config['top_k'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42ad35ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\igor\\Documents\\UCSD\\CSE190_Ammanbdrolu\\cse-190-final-project\\.venv\\Lib\\site-packages\\pygame\\pkgdata.py:25: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import resource_stream, resource_exists\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "import numpy as np\n",
    "from env import create_env\n",
    "from algorithms.a2c import A2CAgent\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "SEED = 42\n",
    "ENV_CONFIG = './configs/env.yaml'\n",
    "MODEL_CONFIG = './configs/a2c.yaml'\n",
    "MODEL_PATH = './models/a2c.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5855faf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "observation: {'type': 'Kinematics', 'vehicles_count': 10, 'features': ['presence', 'x', 'y', 'vx', 'vy', 'cos_h', 'sin_h'], 'features_range': {'x': [-100, 100], 'y': [-100, 100], 'vx': [-20, 20], 'vy': [-20, 20]}, 'absolute': False, 'sorted': True}\n",
      "action: {'type': 'ContinuousAction'}\n",
      "simulation_frequency: 15\n",
      "policy_frequency: 2\n",
      "other_vehicles_type: highway_env.vehicle.behavior.IDMVehicle\n",
      "screen_width: 600\n",
      "screen_height: 600\n",
      "centering_position: [0.5, 0.6]\n",
      "scaling: 7.15\n",
      "show_trajectories: False\n",
      "render_agent: True\n",
      "offscreen_rendering: False\n",
      "manual_control: False\n",
      "real_time_rendering: False\n",
      "duration: 50\n",
      "destination: o1\n",
      "controlled_vehicles: 1\n",
      "initial_vehicle_count: 10\n",
      "spawn_probability: 0.6\n",
      "collision_reward: -100.0\n",
      "high_speed_reward: 0.0\n",
      "arrived_reward: 50.0\n",
      "reward_speed_range: [0.0, 3.0]\n",
      "normalize_reward: False\n",
      "offroad_terminal: True\n",
      "vehicle: {'acceleration': 3.0, 'steering': 0.4}\n",
      "collision_terminal: True\n"
     ]
    }
   ],
   "source": [
    "env = create_env(\n",
    "    config_filepath=ENV_CONFIG,\n",
    "    render_mode=None,\n",
    ")\n",
    "env.reset(seed=SEED)\n",
    "\n",
    "# Display env configs\n",
    "for key in env.config.keys():\n",
    "    print(f'{key}: {env.config[key]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9723e3d",
   "metadata": {},
   "source": [
    "## Load Model Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7b824c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hidden_size: 128\n",
      "learning_rate: 0.005\n",
      "gamma: 0.95\n",
      "num_episodes_train: 3000\n",
      "print_freq: 100\n",
      "save_freq: 1000\n",
      "num_episodes_eval: 100\n",
      "top_k: 5\n"
     ]
    }
   ],
   "source": [
    "with open(MODEL_CONFIG, 'r') as file:\n",
    "    config = yaml.safe_load(file)\n",
    "\n",
    "for key in config.keys():\n",
    "    print(f'{key}: {config[key]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94399219",
   "metadata": {},
   "source": [
    "## Create Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f1f9e605",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State size: 70, Action size: 2\n"
     ]
    }
   ],
   "source": [
    "state_size = np.prod(env.observation_space.shape)\n",
    "action_size = env.action_space.shape[0]\n",
    "print(f\"State size: {state_size}, Action size: {action_size}\")\n",
    "agent = A2CAgent(\n",
    "    state_size=state_size,\n",
    "    hidden_size=config['hidden_size'],\n",
    "    action_size=action_size,\n",
    "    learning_rate=config['learning_rate'],\n",
    "    gamma=config['gamma'],\n",
    "    model_path=MODEL_PATH,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa6572a8",
   "metadata": {},
   "source": [
    "## Train Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "64d96ad3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training A2C Agent:   0%|          | 1/3000 [00:00<05:21,  9.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max reward: 1.00 at episode 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training A2C Agent:   3%|▎         | 100/3000 [00:22<09:05,  5.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 100/3000 | Max reward: 1.00 | Avg reward: 1.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training A2C Agent:   7%|▋         | 200/3000 [00:37<06:39,  7.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 200/3000 | Max reward: 1.00 | Avg reward: 1.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training A2C Agent:  10%|█         | 301/3000 [00:59<06:29,  6.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 300/3000 | Max reward: 1.00 | Avg reward: 1.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training A2C Agent:  13%|█▎        | 401/3000 [01:18<06:49,  6.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 400/3000 | Max reward: 1.00 | Avg reward: 1.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training A2C Agent:  17%|█▋        | 501/3000 [01:36<07:25,  5.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 500/3000 | Max reward: 1.00 | Avg reward: 1.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training A2C Agent:  20%|██        | 601/3000 [01:56<06:43,  5.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 600/3000 | Max reward: 1.00 | Avg reward: 1.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training A2C Agent:  21%|██        | 626/3000 [02:02<07:02,  5.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max reward: 2.00 at episode 625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training A2C Agent:  23%|██▎       | 701/3000 [02:15<07:19,  5.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 700/3000 | Max reward: 2.00 | Avg reward: 1.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training A2C Agent:  25%|██▍       | 737/3000 [02:21<04:54,  7.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max reward: 3.00 at episode 736\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training A2C Agent:  27%|██▋       | 800/3000 [02:33<06:38,  5.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 800/3000 | Max reward: 3.00 | Avg reward: 1.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training A2C Agent:  30%|███       | 901/3000 [03:00<08:51,  3.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 900/3000 | Max reward: 3.00 | Avg reward: 1.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training A2C Agent:  33%|███▎      | 1001/3000 [03:20<06:42,  4.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1000/3000 | Max reward: 3.00 | Avg reward: 1.01\n",
      "Model saved to ./models/a2c_ep1000.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training A2C Agent:  37%|███▋      | 1101/3000 [03:43<05:03,  6.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1100/3000 | Max reward: 3.00 | Avg reward: 1.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training A2C Agent:  40%|███▉      | 1192/3000 [04:10<09:02,  3.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max reward: 5.00 at episode 1192\n",
      "Model saved to ./models/a2c.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training A2C Agent:  40%|████      | 1201/3000 [04:13<07:27,  4.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1200/3000 | Max reward: 5.00 | Avg reward: 1.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training A2C Agent:  43%|████▎     | 1300/3000 [04:42<13:09,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1300/3000 | Max reward: 5.00 | Avg reward: 1.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training A2C Agent:  47%|████▋     | 1401/3000 [05:10<04:51,  5.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1400/3000 | Max reward: 5.00 | Avg reward: 1.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training A2C Agent:  50%|█████     | 1500/3000 [05:27<04:23,  5.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1500/3000 | Max reward: 5.00 | Avg reward: 1.03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training A2C Agent:  53%|█████▎    | 1602/3000 [05:45<02:57,  7.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1600/3000 | Max reward: 5.00 | Avg reward: 1.03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training A2C Agent:  57%|█████▋    | 1701/3000 [06:00<02:47,  7.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1700/3000 | Max reward: 5.00 | Avg reward: 1.04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training A2C Agent:  60%|██████    | 1801/3000 [06:16<02:56,  6.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1800/3000 | Max reward: 5.00 | Avg reward: 1.04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training A2C Agent:  63%|██████▎   | 1901/3000 [06:32<02:29,  7.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1900/3000 | Max reward: 5.00 | Avg reward: 1.04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training A2C Agent:  67%|██████▋   | 2000/3000 [06:54<02:11,  7.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 2000/3000 | Max reward: 5.00 | Avg reward: 1.04\n",
      "Model saved to ./models/a2c_ep2000.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training A2C Agent:  70%|███████   | 2101/3000 [07:14<02:54,  5.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 2100/3000 | Max reward: 5.00 | Avg reward: 1.04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training A2C Agent:  73%|███████▎  | 2200/3000 [08:08<06:03,  2.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 2200/3000 | Max reward: 5.00 | Avg reward: 1.04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training A2C Agent:  77%|███████▋  | 2301/3000 [08:22<01:12,  9.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 2300/3000 | Max reward: 5.00 | Avg reward: 1.04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training A2C Agent:  80%|████████  | 2401/3000 [08:34<01:10,  8.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 2400/3000 | Max reward: 5.00 | Avg reward: 1.04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training A2C Agent:  83%|████████▎ | 2501/3000 [08:45<00:48, 10.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 2500/3000 | Max reward: 5.00 | Avg reward: 1.03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training A2C Agent:  87%|████████▋ | 2601/3000 [08:55<00:40,  9.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 2600/3000 | Max reward: 5.00 | Avg reward: 1.03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training A2C Agent:  90%|█████████ | 2701/3000 [09:05<00:36,  8.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 2700/3000 | Max reward: 5.00 | Avg reward: 1.03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training A2C Agent:  93%|█████████▎| 2801/3000 [09:16<00:21,  9.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 2800/3000 | Max reward: 5.00 | Avg reward: 1.03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training A2C Agent:  97%|█████████▋| 2899/3000 [09:26<00:11,  8.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 2900/3000 | Max reward: 5.00 | Avg reward: 1.03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training A2C Agent: 100%|██████████| 3000/3000 [09:48<00:00,  5.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 3000/3000 | Max reward: 5.00 | Avg reward: 1.03\n",
      "Model saved to ./models/a2c_ep3000.pth\n",
      "Training completed. Avg reward: 1.03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "agent.train(\n",
    "    env=env,\n",
    "    num_episodes=config['num_episodes_train'],\n",
    "    print_freq=config['print_freq'],\n",
    "    save_freq=config['save_freq'],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "366be4a0",
   "metadata": {},
   "source": [
    "## Save Model Weights if Desired\n",
    "#### Highest reward runs during training are automatically saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ada83a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to ./models/a2c.pth\n"
     ]
    }
   ],
   "source": [
    "agent.save_model(\n",
    "    model_path=MODEL_PATH,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aad0ccd",
   "metadata": {},
   "source": [
    "## Evaluate Agent Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b1f0abef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "observation: {'type': 'Kinematics', 'vehicles_count': 10, 'features': ['presence', 'x', 'y', 'vx', 'vy', 'cos_h', 'sin_h'], 'features_range': {'x': [-100, 100], 'y': [-100, 100], 'vx': [-20, 20], 'vy': [-20, 20]}, 'absolute': False, 'sorted': True}\n",
      "action: {'type': 'ContinuousAction'}\n",
      "simulation_frequency: 15\n",
      "policy_frequency: 2\n",
      "other_vehicles_type: highway_env.vehicle.behavior.IDMVehicle\n",
      "screen_width: 600\n",
      "screen_height: 600\n",
      "centering_position: [0.5, 0.6]\n",
      "scaling: 7.15\n",
      "show_trajectories: False\n",
      "render_agent: True\n",
      "offscreen_rendering: False\n",
      "manual_control: False\n",
      "real_time_rendering: False\n",
      "duration: 50\n",
      "destination: o1\n",
      "controlled_vehicles: 1\n",
      "initial_vehicle_count: 10\n",
      "spawn_probability: 0.6\n",
      "collision_reward: -100.0\n",
      "high_speed_reward: 0.0\n",
      "arrived_reward: 50.0\n",
      "reward_speed_range: [0.0, 3.0]\n",
      "normalize_reward: False\n",
      "offroad_terminal: True\n",
      "vehicle: {'acceleration': 3.0, 'steering': 0.4}\n",
      "collision_terminal: True\n"
     ]
    }
   ],
   "source": [
    "eval_env = create_env(\n",
    "    config_filepath=ENV_CONFIG,\n",
    "    render_mode='rgb_array',\n",
    ")\n",
    "eval_env.reset(seed=SEED)\n",
    "\n",
    "# Display env configs\n",
    "for key in eval_env.config.keys():\n",
    "    print(f'{key}: {eval_env.config[key]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "de498d72",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating A2C Agent: 100%|██████████| 100/100 [00:27<00:00,  3.67it/s]\n"
     ]
    }
   ],
   "source": [
    "agent.evaluate(\n",
    "    env=eval_env,\n",
    "    num_episodes=config['num_episodes_eval'],\n",
    "    top_k=config['top_k'],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df9c4fd2",
   "metadata": {},
   "source": [
    "## Flops Measurement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "52283eda",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsupported operator aten::tanh encountered 2 time(s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FLOPs: 25984\n",
      "Counter({'linear': 25984})\n"
     ]
    }
   ],
   "source": [
    "from fvcore.nn import FlopCountAnalysis\n",
    "import torch\n",
    "\n",
    "a2c_agent = agent\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "inputs = (torch.randn(1, state_size).to(device),)  # Example input shape\n",
    "\n",
    "flops = FlopCountAnalysis(a2c_agent.model, inputs)\n",
    "print(f\"FLOPs: {flops.total()}\")  # Total FLOPs\n",
    "print(flops.by_operator())        # FLOPs by operator (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf63d66",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
