{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86dda4c5",
   "metadata": {},
   "source": [
    "# A2C (Advantage Actor-Critic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bf68b89c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment configuration:\n",
      "observation: {'type': 'Kinematics', 'vehicles_count': 10, 'features': ['presence', 'x', 'y', 'vx', 'vy', 'cos_h', 'sin_h'], 'features_range': {'x': [-100, 100], 'y': [-100, 100], 'vx': [-20, 20], 'vy': [-20, 20]}, 'absolute': False, 'sorted': True}\n",
      "action: {'type': 'ContinuousAction'}\n",
      "simulation_frequency: 15\n",
      "policy_frequency: 2\n",
      "other_vehicles_type: highway_env.vehicle.behavior.IDMVehicle\n",
      "screen_width: 600\n",
      "screen_height: 600\n",
      "centering_position: [0.5, 0.6]\n",
      "scaling: 7.15\n",
      "show_trajectories: False\n",
      "render_agent: True\n",
      "offscreen_rendering: False\n",
      "manual_control: False\n",
      "real_time_rendering: False\n",
      "duration: 50\n",
      "destination: o1\n",
      "controlled_vehicles: 1\n",
      "initial_vehicle_count: 10\n",
      "spawn_probability: 0.6\n",
      "collision_reward: -100.0\n",
      "high_speed_reward: 0.0\n",
      "arrived_reward: 50.0\n",
      "reward_speed_range: [0.0, 3.0]\n",
      "normalize_reward: False\n",
      "offroad_terminal: True\n",
      "vehicle: {'acceleration': 3.0, 'steering': 0.4}\n",
      "collision_terminal: True\n",
      "Model configuration:\n",
      "{'hidden_size': 64, 'learning_rate': 0.001, 'gamma': 0.8, 'num_episodes_train': 3000, 'print_freq': 100, 'save_freq': 1000, 'num_episodes_eval': 100, 'top_k': 5}\n",
      "State size: 70, Action size: 2\n",
      "Model loaded from ./models/a2c_ep1000.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating A2C Agent: 100%|██████████| 100/100 [00:15<00:00,  6.51it/s]\n"
     ]
    }
   ],
   "source": [
    "### One-cell script to run evaluation\n",
    "import yaml\n",
    "import numpy as np\n",
    "from env import create_env\n",
    "from algorithms.a2c import A2CAgent\n",
    "\n",
    "SEED = 42\n",
    "ENV_CONFIG = './configs/env.yaml'\n",
    "MODEL_CONFIG = './configs/a2c.yaml'\n",
    "MODEL_PATH = './models/a2c_ep1000.pth'\n",
    "\n",
    "eval_env = create_env(\n",
    "    config_filepath=ENV_CONFIG,\n",
    "    render_mode='rgb_array',\n",
    ")\n",
    "eval_env.reset(seed=SEED)\n",
    "\n",
    "# Display env configs\n",
    "print(\"Environment configuration:\")\n",
    "for key in eval_env.config.keys():\n",
    "    print(f'{key}: {eval_env.config[key]}')\n",
    "\n",
    "with open(MODEL_CONFIG, 'r') as file:\n",
    "    config = yaml.safe_load(file)\n",
    "    print(\"Model configuration:\")\n",
    "    print(config)\n",
    "\n",
    "state_size = np.prod(eval_env.observation_space.shape)\n",
    "action_size = eval_env.action_space.shape[0]\n",
    "print(f\"State size: {state_size}, Action size: {action_size}\")\n",
    "agent = A2CAgent(\n",
    "    state_size=state_size,\n",
    "    hidden_size=config['hidden_size'],\n",
    "    action_size=action_size,\n",
    "    learning_rate=config['learning_rate'],\n",
    "    gamma=config['gamma'],\n",
    "    model_path=MODEL_PATH,\n",
    ")\n",
    "\n",
    "agent.load_model(\n",
    "    model_path=MODEL_PATH,\n",
    ")\n",
    "\n",
    "agent.evaluate(\n",
    "    env=eval_env,\n",
    "    num_episodes=config['num_episodes_eval'],\n",
    "    top_k=config['top_k'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42ad35ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import numpy as np\n",
    "from env import create_env\n",
    "from algorithms.a2c import A2CAgent\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "SEED = 42\n",
    "ENV_CONFIG = './configs/env.yaml'\n",
    "MODEL_CONFIG = './configs/a2c.yaml'\n",
    "MODEL_PATH = './models/a2c.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5855faf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "observation: {'type': 'Kinematics', 'vehicles_count': 10, 'features': ['presence', 'x', 'y', 'vx', 'vy', 'cos_h', 'sin_h'], 'features_range': {'x': [-100, 100], 'y': [-100, 100], 'vx': [-20, 20], 'vy': [-20, 20]}, 'absolute': False, 'sorted': True}\n",
      "action: {'type': 'ContinuousAction'}\n",
      "simulation_frequency: 15\n",
      "policy_frequency: 2\n",
      "other_vehicles_type: highway_env.vehicle.behavior.IDMVehicle\n",
      "screen_width: 600\n",
      "screen_height: 600\n",
      "centering_position: [0.5, 0.6]\n",
      "scaling: 7.15\n",
      "show_trajectories: False\n",
      "render_agent: True\n",
      "offscreen_rendering: False\n",
      "manual_control: False\n",
      "real_time_rendering: False\n",
      "duration: 50\n",
      "destination: o1\n",
      "controlled_vehicles: 1\n",
      "initial_vehicle_count: 10\n",
      "spawn_probability: 0.6\n",
      "collision_reward: -100.0\n",
      "high_speed_reward: 0.0\n",
      "arrived_reward: 50.0\n",
      "reward_speed_range: [0.0, 3.0]\n",
      "normalize_reward: False\n",
      "offroad_terminal: True\n",
      "vehicle: {'acceleration': 3.0, 'steering': 0.4}\n",
      "collision_terminal: True\n"
     ]
    }
   ],
   "source": [
    "env = create_env(\n",
    "    config_filepath=ENV_CONFIG,\n",
    "    render_mode=None,\n",
    ")\n",
    "env.reset(seed=SEED)\n",
    "\n",
    "# Display env configs\n",
    "for key in env.config.keys():\n",
    "    print(f'{key}: {env.config[key]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9723e3d",
   "metadata": {},
   "source": [
    "## Load Model Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7b824c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hidden_size: 64\n",
      "learning_rate: 0.001\n",
      "gamma: 0.8\n",
      "num_episodes_train: 3000\n",
      "print_freq: 100\n",
      "save_freq: 1000\n",
      "num_episodes_eval: 100\n",
      "top_k: 5\n"
     ]
    }
   ],
   "source": [
    "with open(MODEL_CONFIG, 'r') as file:\n",
    "    config = yaml.safe_load(file)\n",
    "\n",
    "for key in config.keys():\n",
    "    print(f'{key}: {config[key]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94399219",
   "metadata": {},
   "source": [
    "## Create Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f1f9e605",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State size: 70, Action size: 2\n"
     ]
    }
   ],
   "source": [
    "state_size = np.prod(env.observation_space.shape)\n",
    "action_size = env.action_space.shape[0]\n",
    "print(f\"State size: {state_size}, Action size: {action_size}\")\n",
    "agent = A2CAgent(\n",
    "    state_size=state_size,\n",
    "    hidden_size=config['hidden_size'],\n",
    "    action_size=action_size,\n",
    "    learning_rate=config['learning_rate'],\n",
    "    gamma=config['gamma'],\n",
    "    model_path=MODEL_PATH,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa6572a8",
   "metadata": {},
   "source": [
    "## Train Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "64d96ad3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training A2C Agent:   0%|          | 2/3000 [00:00<07:10,  6.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max reward: 1.00 at episode 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training A2C Agent:   1%|          | 23/3000 [00:02<08:19,  5.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max reward: 4.00 at episode 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training A2C Agent:   3%|▎         | 101/3000 [00:12<06:08,  7.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 100/3000 | Max reward: 4.00 | Avg reward: 1.06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training A2C Agent:   7%|▋         | 201/3000 [00:27<05:54,  7.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 200/3000 | Max reward: 4.00 | Avg reward: 1.03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training A2C Agent:  10%|█         | 302/3000 [00:42<04:17, 10.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 300/3000 | Max reward: 4.00 | Avg reward: 1.03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training A2C Agent:  13%|█▎        | 401/3000 [00:56<05:33,  7.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 400/3000 | Max reward: 4.00 | Avg reward: 1.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training A2C Agent:  17%|█▋        | 501/3000 [01:14<05:28,  7.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 500/3000 | Max reward: 4.00 | Avg reward: 1.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training A2C Agent:  20%|██        | 600/3000 [01:27<06:10,  6.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 600/3000 | Max reward: 4.00 | Avg reward: 1.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training A2C Agent:  23%|██▎       | 701/3000 [01:42<05:27,  7.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 700/3000 | Max reward: 4.00 | Avg reward: 1.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training A2C Agent:  27%|██▋       | 800/3000 [01:56<03:34, 10.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 800/3000 | Max reward: 4.00 | Avg reward: 1.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training A2C Agent:  30%|███       | 900/3000 [02:11<03:38,  9.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 900/3000 | Max reward: 4.00 | Avg reward: 1.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training A2C Agent:  33%|███▎      | 1001/3000 [02:27<05:59,  5.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1000/3000 | Max reward: 4.00 | Avg reward: 1.02\n",
      "Model saved to ./models/a2c_ep1000.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training A2C Agent:  37%|███▋      | 1100/3000 [02:42<05:07,  6.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1100/3000 | Max reward: 4.00 | Avg reward: 1.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training A2C Agent:  40%|████      | 1200/3000 [02:56<03:53,  7.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1200/3000 | Max reward: 4.00 | Avg reward: 1.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training A2C Agent:  43%|████▎     | 1300/3000 [03:11<03:12,  8.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1300/3000 | Max reward: 4.00 | Avg reward: 1.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training A2C Agent:  47%|████▋     | 1401/3000 [03:25<03:11,  8.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1400/3000 | Max reward: 4.00 | Avg reward: 1.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training A2C Agent:  50%|█████     | 1501/3000 [03:40<03:06,  8.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1500/3000 | Max reward: 4.00 | Avg reward: 1.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training A2C Agent:  53%|█████▎    | 1601/3000 [03:55<02:47,  8.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1600/3000 | Max reward: 4.00 | Avg reward: 1.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training A2C Agent:  54%|█████▍    | 1621/3000 [03:58<05:37,  4.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max reward: 5.00 at episode 1620\n",
      "Model saved to ./models/a2c.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training A2C Agent:  57%|█████▋    | 1700/3000 [04:10<02:29,  8.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1700/3000 | Max reward: 5.00 | Avg reward: 1.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training A2C Agent:  60%|██████    | 1801/3000 [04:25<02:23,  8.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1800/3000 | Max reward: 5.00 | Avg reward: 1.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training A2C Agent:  63%|██████▎   | 1900/3000 [04:40<01:53,  9.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1900/3000 | Max reward: 5.00 | Avg reward: 1.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training A2C Agent:  67%|██████▋   | 2002/3000 [04:55<02:53,  5.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 2000/3000 | Max reward: 5.00 | Avg reward: 1.02\n",
      "Model saved to ./models/a2c_ep2000.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training A2C Agent:  70%|███████   | 2101/3000 [05:11<01:57,  7.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 2100/3000 | Max reward: 5.00 | Avg reward: 1.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training A2C Agent:  73%|███████▎  | 2200/3000 [05:27<01:54,  6.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 2200/3000 | Max reward: 5.00 | Avg reward: 1.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training A2C Agent:  75%|███████▌  | 2259/3000 [05:38<03:11,  3.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max reward: 6.00 at episode 2259\n",
      "Model saved to ./models/a2c.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training A2C Agent:  77%|███████▋  | 2301/3000 [05:45<01:49,  6.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 2300/3000 | Max reward: 6.00 | Avg reward: 1.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training A2C Agent:  80%|████████  | 2400/3000 [06:02<01:03,  9.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 2400/3000 | Max reward: 6.00 | Avg reward: 1.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training A2C Agent:  83%|████████▎ | 2501/3000 [06:17<00:48, 10.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 2500/3000 | Max reward: 6.00 | Avg reward: 1.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training A2C Agent:  87%|████████▋ | 2602/3000 [06:34<00:42,  9.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 2600/3000 | Max reward: 6.00 | Avg reward: 1.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training A2C Agent:  90%|█████████ | 2700/3000 [06:53<00:47,  6.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 2700/3000 | Max reward: 6.00 | Avg reward: 1.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training A2C Agent:  93%|█████████▎| 2801/3000 [07:10<00:30,  6.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 2800/3000 | Max reward: 6.00 | Avg reward: 1.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training A2C Agent:  97%|█████████▋| 2901/3000 [07:29<00:18,  5.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 2900/3000 | Max reward: 6.00 | Avg reward: 1.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training A2C Agent:  97%|█████████▋| 2914/3000 [07:33<00:43,  1.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max reward: 7.00 at episode 2914\n",
      "Model saved to ./models/a2c.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training A2C Agent: 100%|██████████| 3000/3000 [07:49<00:00,  6.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 3000/3000 | Max reward: 7.00 | Avg reward: 1.02\n",
      "Model saved to ./models/a2c_ep3000.pth\n",
      "Training completed. Avg reward: 1.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "agent.train(\n",
    "    env=env,\n",
    "    num_episodes=config['num_episodes_train'],\n",
    "    print_freq=config['print_freq'],\n",
    "    save_freq=config['save_freq'],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "366be4a0",
   "metadata": {},
   "source": [
    "## Save Model Weights if Desired\n",
    "#### Highest reward runs during training are automatically saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ada83a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to ./models/a2c.pth\n"
     ]
    }
   ],
   "source": [
    "agent.save_model(\n",
    "    model_path=MODEL_PATH,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aad0ccd",
   "metadata": {},
   "source": [
    "## Evaluate Agent Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b1f0abef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "observation: {'type': 'Kinematics', 'vehicles_count': 10, 'features': ['presence', 'x', 'y', 'vx', 'vy', 'cos_h', 'sin_h'], 'features_range': {'x': [-100, 100], 'y': [-100, 100], 'vx': [-20, 20], 'vy': [-20, 20]}, 'absolute': False, 'sorted': True}\n",
      "action: {'type': 'ContinuousAction'}\n",
      "simulation_frequency: 15\n",
      "policy_frequency: 2\n",
      "other_vehicles_type: highway_env.vehicle.behavior.IDMVehicle\n",
      "screen_width: 600\n",
      "screen_height: 600\n",
      "centering_position: [0.5, 0.6]\n",
      "scaling: 7.15\n",
      "show_trajectories: False\n",
      "render_agent: True\n",
      "offscreen_rendering: False\n",
      "manual_control: False\n",
      "real_time_rendering: False\n",
      "duration: 50\n",
      "destination: o1\n",
      "controlled_vehicles: 1\n",
      "initial_vehicle_count: 10\n",
      "spawn_probability: 0.6\n",
      "collision_reward: -100.0\n",
      "high_speed_reward: 0.0\n",
      "arrived_reward: 50.0\n",
      "reward_speed_range: [0.0, 3.0]\n",
      "normalize_reward: False\n",
      "offroad_terminal: True\n",
      "vehicle: {'acceleration': 3.0, 'steering': 0.4}\n",
      "collision_terminal: True\n"
     ]
    }
   ],
   "source": [
    "eval_env = create_env(\n",
    "    config_filepath=ENV_CONFIG,\n",
    "    render_mode='rgb_array',\n",
    ")\n",
    "eval_env.reset(seed=SEED)\n",
    "\n",
    "# Display env configs\n",
    "for key in eval_env.config.keys():\n",
    "    print(f'{key}: {eval_env.config[key]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "de498d72",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating A2C Agent: 100%|██████████| 100/100 [00:20<00:00,  4.92it/s]\n"
     ]
    }
   ],
   "source": [
    "agent.evaluate(\n",
    "    env=eval_env,\n",
    "    num_episodes=config['num_episodes_eval'],\n",
    "    top_k=config['top_k'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf63d66",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
