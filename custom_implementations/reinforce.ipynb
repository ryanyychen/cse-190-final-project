{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52d913db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86dda4c5",
   "metadata": {},
   "source": [
    "# REINFORCE (Policy Gradient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf68b89c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment configuration:\n",
      "observation: {'type': 'Kinematics', 'vehicles_count': 10, 'features': ['presence', 'x', 'y', 'vx', 'vy', 'cos_h', 'sin_h'], 'features_range': {'x': [-100, 100], 'y': [-100, 100], 'vx': [-20, 20], 'vy': [-20, 20]}, 'absolute': False, 'sorted': True}\n",
      "action: {'type': 'ContinuousAction'}\n",
      "simulation_frequency: 15\n",
      "policy_frequency: 2\n",
      "other_vehicles_type: highway_env.vehicle.behavior.IDMVehicle\n",
      "screen_width: 600\n",
      "screen_height: 600\n",
      "centering_position: [0.5, 0.6]\n",
      "scaling: 7.15\n",
      "show_trajectories: False\n",
      "render_agent: True\n",
      "offscreen_rendering: False\n",
      "manual_control: False\n",
      "real_time_rendering: False\n",
      "duration: 50\n",
      "destination: o1\n",
      "controlled_vehicles: 1\n",
      "initial_vehicle_count: 10\n",
      "spawn_probability: 0.6\n",
      "collision_reward: -100.0\n",
      "high_speed_reward: 0.0\n",
      "arrived_reward: 50.0\n",
      "reward_speed_range: [0.0, 3.0]\n",
      "normalize_reward: False\n",
      "offroad_terminal: True\n",
      "vehicle: {'acceleration': 3.0, 'steering': 0.4}\n",
      "collision_terminal: True\n",
      "Model configuration:\n",
      "{'hidden_size': 128, 'learning_rate': 0.001, 'gamma': 0.95, 'num_episodes_train': 3000, 'print_freq': 100, 'save_freq': 1000, 'num_episodes_eval': 100, 'top_k': 5}\n",
      "State size: 70, Action size: 2\n",
      "Using device: cpu\n",
      "Model loaded from ./models/models_o1/reinforce_best.pth\n",
      "Model FLOPs: 25856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating REINFORCE Agent:   1%|          | 1/100 [00:03<06:21,  3.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 0 completed with reward 28.00 and 30 frames\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating REINFORCE Agent:   2%|▏         | 2/100 [00:06<05:11,  3.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1 completed with reward 27.00 and 30 frames\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating REINFORCE Agent:   3%|▎         | 3/100 [00:06<03:06,  1.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during episode 2: 'NoneType' object has no attribute 'get_image'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating REINFORCE Agent:   4%|▍         | 4/100 [00:09<03:21,  2.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 3 completed with reward 29.00 and 30 frames\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "### One-cell script to run evaluation\n",
    "import yaml\n",
    "import numpy as np\n",
    "from env import create_env\n",
    "from algorithms.reinforce import REINFORCEAgent\n",
    "\n",
    "SEED = 42\n",
    "ENV_CONFIG = './configs/env.yaml'\n",
    "MODEL_CONFIG = './configs/reinforce.yaml'\n",
    "MODEL_PATH = './models/models_o1/reinforce_best.pth'\n",
    "# MODEL_PATH = './models_o1/reinforce_ep1000.pth'\n",
    "# MODEL_PATH = './models_o1/reinforce_ep2000.pth'\n",
    "# MODEL_PATH = './models_o1/reinforce_ep3000.pth'\n",
    "# MODEL_PATH = './models_o2/reinforce_best.pth'\n",
    "# MODEL_PATH = './models_o2/reinforce_ep1000.pth'\n",
    "\n",
    "eval_env = create_env(\n",
    "    config_filepath=ENV_CONFIG,\n",
    "    render_mode='rgb_array',\n",
    ")\n",
    "eval_env.reset(seed=SEED)\n",
    "\n",
    "# Set rendering parameters\n",
    "# eval_env.config.update({\n",
    "#     'offscreen_rendering': False,\n",
    "#     'real_time_rendering': True,\n",
    "#     'render_agent': True,\n",
    "#     'show_trajectories': False\n",
    "# })\n",
    "\n",
    "\n",
    "# Display env configs\n",
    "print(\"Environment configuration:\")\n",
    "for key in eval_env.config.keys():\n",
    "    print(f'{key}: {eval_env.config[key]}')\n",
    "\n",
    "with open(MODEL_CONFIG, 'r') as file:\n",
    "    config = yaml.safe_load(file)\n",
    "    print(\"Model configuration:\")\n",
    "    print(config)\n",
    "\n",
    "state_size = np.prod(eval_env.observation_space.shape)\n",
    "action_size = eval_env.action_space.shape[0]\n",
    "print(f\"State size: {state_size}, Action size: {action_size}\")\n",
    "agent = REINFORCEAgent(\n",
    "    state_size=state_size,\n",
    "    hidden_size=config['hidden_size'],\n",
    "    action_size=action_size,\n",
    "    learning_rate=config['learning_rate'],\n",
    "    gamma=config['gamma'],\n",
    "    model_path=MODEL_PATH,\n",
    ")\n",
    "\n",
    "agent.load_model(\n",
    "    model_path=MODEL_PATH,\n",
    ")\n",
    "\n",
    "agent.evaluate(\n",
    "    env=eval_env,\n",
    "    num_episodes=config['num_episodes_eval'],\n",
    "    top_k=config['top_k'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42ad35ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import numpy as np\n",
    "from custom_implementations.env import create_env\n",
    "from algorithms.reinforce import REINFORCEAgent\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "SEED = 42\n",
    "ENV_CONFIG = './configs/env.yaml'\n",
    "MODEL_CONFIG = './configs/reinforce.yaml'\n",
    "MODEL_PATH = './models/models_o1/reinforce.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5855faf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "observation: {'type': 'Kinematics', 'vehicles_count': 10, 'features': ['presence', 'x', 'y', 'vx', 'vy', 'cos_h', 'sin_h'], 'features_range': {'x': [-100, 100], 'y': [-100, 100], 'vx': [-20, 20], 'vy': [-20, 20]}, 'absolute': False, 'sorted': True, 'normalize': True, 'include_road_info': True, 'include_vehicle_info': True, 'include_goal_info': True, 'history_length': 5}\n",
      "action: {'type': 'ContinuousAction', 'continuous': True, 'normalize': True, 'clip_actions': True}\n",
      "simulation_frequency: 10\n",
      "policy_frequency: 10\n",
      "other_vehicles_type: highway_env.vehicle.behavior.IDMVehicle\n",
      "screen_width: 600\n",
      "screen_height: 600\n",
      "centering_position: [0.5, 0.6]\n",
      "scaling: 7.15\n",
      "show_trajectories: False\n",
      "render_agent: True\n",
      "offscreen_rendering: False\n",
      "manual_control: False\n",
      "real_time_rendering: False\n",
      "duration: 100\n",
      "destination: o1\n",
      "controlled_vehicles: 1\n",
      "initial_vehicle_count: 10\n",
      "spawn_probability: 0.6\n",
      "collision_reward: -20.0\n",
      "high_speed_reward: 0.1\n",
      "arrived_reward: 50.0\n",
      "reward_speed_range: [0.0, 3.0]\n",
      "normalize_reward: True\n",
      "offroad_terminal: True\n",
      "safe_distance_reward: -4.0\n",
      "route_reward: 2.5\n",
      "progress_reward: 2.0\n",
      "speed_reward: 1.5\n",
      "lane_following_reward: -2.0\n",
      "turning_reward: 3.0\n",
      "consistency_reward: 1.0\n",
      "vehicle: {'length': 4.5, 'width': 2.0, 'max_speed': 20.0, 'acceleration': 2.0, 'steering': 0.5, 'min_speed': 0.0, 'max_steering_angle': 0.5, 'wheel_base': 2.7, 'max_acceleration': 2.0, 'max_deceleration': 4.0, 'max_steering_speed': 0.5}\n",
      "collision_terminal: True\n",
      "off_road_reward: -5.0\n",
      "lane_keeping_reward: 0.5\n",
      "rewards: {'collision_reward': -20.0, 'high_speed_reward': 0.1, 'arrived_reward': 50.0, 'normalize_reward': True, 'off_road_penalty': -5.0, 'steering_penalty': -0.1, 'acceleration_penalty': -0.05, 'progress_reward': 0.5, 'distance_reward': 0.1, 'speed_reward': 0.2, 'heading_reward': 0.3}\n",
      "termination: {'max_steps': 500, 'min_steps': 30, 'max_off_road_time': 2.0, 'max_collision_time': 1.0}\n"
     ]
    }
   ],
   "source": [
    "env = create_env(\n",
    "    config_filepath=ENV_CONFIG,\n",
    "    render_mode=None,\n",
    ")\n",
    "env.reset(seed=SEED)\n",
    "\n",
    "# Display env configs\n",
    "for key in env.config.keys():\n",
    "    print(f'{key}: {env.config[key]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9723e3d",
   "metadata": {},
   "source": [
    "## Load Model Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7b824c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hidden_size: 128\n",
      "learning_rate: 0.001\n",
      "gamma: 0.95\n",
      "num_episodes_train: 3000\n",
      "print_freq: 100\n",
      "save_freq: 1000\n",
      "num_episodes_eval: 100\n",
      "top_k: 5\n"
     ]
    }
   ],
   "source": [
    "with open(MODEL_CONFIG, 'r') as file:\n",
    "    config = yaml.safe_load(file)\n",
    "\n",
    "for key in config.keys():\n",
    "    print(f'{key}: {config[key]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94399219",
   "metadata": {},
   "source": [
    "## Create Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f1f9e605",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State size: 70, Action size: 2\n",
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "state_size = np.prod(env.observation_space.shape)\n",
    "action_size = env.action_space.shape[0]\n",
    "print(f\"State size: {state_size}, Action size: {action_size}\")\n",
    "agent = REINFORCEAgent(\n",
    "    state_size=state_size,\n",
    "    hidden_size=config['hidden_size'],\n",
    "    action_size=action_size,\n",
    "    learning_rate=config['learning_rate'],\n",
    "    gamma=config['gamma'],\n",
    "    model_path=MODEL_PATH,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa6572a8",
   "metadata": {},
   "source": [
    "## Train Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "64d96ad3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training REINFORCE Agent:   0%|          | 1/3000 [00:00<30:17,  1.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max reward: 1.00 at episode 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training REINFORCE Agent:   1%|          | 34/3000 [00:19<1:08:06,  1.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max reward: 2.00 at episode 34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training REINFORCE Agent:   2%|▏         | 45/3000 [00:26<32:57,  1.49it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max reward: 9.00 at episode 45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training REINFORCE Agent:   3%|▎         | 100/3000 [00:52<24:19,  1.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best recent average: 1.09 (consistency ratio: 0.12)\n",
      "Model saved to ./models/models_o1/reinforce_best.pth\n",
      "Episode 100/3000 | Max reward: 9.00 | Avg reward: 1.09 | Recent avg: 1.09 | Consistency ratio: 0.12 | Entropy coef: 0.050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training REINFORCE Agent:   7%|▋         | 200/3000 [01:43<17:44,  2.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 200/3000 | Max reward: 9.00 | Avg reward: 1.08 | Recent avg: 1.07 | Consistency ratio: 0.13 | Entropy coef: 0.050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training REINFORCE Agent:   8%|▊         | 241/3000 [02:03<46:20,  1.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best recent average: 1.14 (consistency ratio: 0.14)\n",
      "Model saved to ./models/models_o1/reinforce_best.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training REINFORCE Agent:  10%|█         | 300/3000 [02:33<24:33,  1.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 300/3000 | Max reward: 9.00 | Avg reward: 1.08 | Recent avg: 1.07 | Consistency ratio: 0.13 | Entropy coef: 0.050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training REINFORCE Agent:  12%|█▏        | 370/3000 [03:18<1:21:00,  1.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best recent average: 1.74 (consistency ratio: 0.03)\n",
      "Model saved to ./models/models_o1/reinforce_best.pth\n",
      "Max reward: 68.00 at episode 370\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training REINFORCE Agent:  13%|█▎        | 379/3000 [03:25<1:11:45,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best recent average: 2.40 (consistency ratio: 0.04)\n",
      "Model saved to ./models/models_o1/reinforce_best.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training REINFORCE Agent:  13%|█▎        | 400/3000 [03:34<17:42,  2.45it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 400/3000 | Max reward: 68.00 | Avg reward: 1.41 | Recent avg: 2.40 | Consistency ratio: 0.04 | Entropy coef: 0.050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training REINFORCE Agent:  17%|█▋        | 500/3000 [04:30<18:53,  2.20it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 500/3000 | Max reward: 68.00 | Avg reward: 1.39 | Recent avg: 1.30 | Consistency ratio: 0.04 | Entropy coef: 0.050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training REINFORCE Agent:  20%|██        | 601/3000 [05:26<19:07,  2.09it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 600/3000 | Max reward: 68.00 | Avg reward: 1.32 | Recent avg: 1.00 | Consistency ratio: 1.00 | Entropy coef: 0.050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training REINFORCE Agent:  23%|██▎       | 700/3000 [06:12<09:02,  4.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 700/3000 | Max reward: 68.00 | Avg reward: 1.37 | Recent avg: 1.65 | Consistency ratio: 0.02 | Entropy coef: 0.050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training REINFORCE Agent:  27%|██▋       | 801/3000 [06:52<12:42,  2.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 800/3000 | Max reward: 68.00 | Avg reward: 1.33 | Recent avg: 1.05 | Consistency ratio: 0.18 | Entropy coef: 0.050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training REINFORCE Agent:  27%|██▋       | 823/3000 [07:07<10:46,  3.37it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max reward: 87.00 at episode 824\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training REINFORCE Agent:  29%|██▉       | 880/3000 [07:42<12:57,  2.72it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reducing exploration due to stagnation (entropy coef: 0.025)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training REINFORCE Agent:  30%|███       | 901/3000 [07:52<15:08,  2.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 900/3000 | Max reward: 87.00 | Avg reward: 1.44 | Recent avg: 2.35 | Consistency ratio: 0.03 | Entropy coef: 0.025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training REINFORCE Agent:  33%|███▎      | 1001/3000 [08:32<07:14,  4.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1000/3000 | Max reward: 87.00 | Avg reward: 1.41 | Recent avg: 1.15 | Consistency ratio: 0.10 | Entropy coef: 0.025\n",
      "Model saved to ./models/models_o1/reinforce_ep1000.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training REINFORCE Agent:  37%|███▋      | 1100/3000 [09:22<08:50,  3.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1100/3000 | Max reward: 87.00 | Avg reward: 1.49 | Recent avg: 2.24 | Consistency ratio: 0.04 | Entropy coef: 0.025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training REINFORCE Agent:  37%|███▋      | 1102/3000 [09:24<24:31,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best recent average: 2.46 (consistency ratio: 0.04)\n",
      "Model saved to ./models/models_o1/reinforce_best.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training REINFORCE Agent:  38%|███▊      | 1129/3000 [09:39<38:27,  1.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best recent average: 2.93 (consistency ratio: 0.05)\n",
      "Model saved to ./models/models_o1/reinforce_best.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training REINFORCE Agent:  39%|███▉      | 1169/3000 [10:00<42:39,  1.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best recent average: 3.36 (consistency ratio: 0.05)\n",
      "Model saved to ./models/models_o1/reinforce_best.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training REINFORCE Agent:  40%|████      | 1200/3000 [10:12<11:50,  2.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1200/3000 | Max reward: 87.00 | Avg reward: 1.56 | Recent avg: 2.36 | Consistency ratio: 0.04 | Entropy coef: 0.025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training REINFORCE Agent:  43%|████▎     | 1300/3000 [11:01<14:00,  2.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1300/3000 | Max reward: 87.00 | Avg reward: 1.62 | Recent avg: 2.33 | Consistency ratio: 0.06 | Entropy coef: 0.025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training REINFORCE Agent:  47%|████▋     | 1400/3000 [11:44<08:06,  3.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1400/3000 | Max reward: 87.00 | Avg reward: 1.59 | Recent avg: 1.25 | Consistency ratio: 0.05 | Entropy coef: 0.025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training REINFORCE Agent:  50%|█████     | 1500/3000 [12:34<39:21,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1500/3000 | Max reward: 87.00 | Avg reward: 1.61 | Recent avg: 1.81 | Consistency ratio: 0.03 | Entropy coef: 0.025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training REINFORCE Agent:  53%|█████▎    | 1600/3000 [13:25<07:20,  3.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1600/3000 | Max reward: 87.00 | Avg reward: 1.63 | Recent avg: 1.99 | Consistency ratio: 0.03 | Entropy coef: 0.025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training REINFORCE Agent:  56%|█████▌    | 1670/3000 [13:58<05:30,  4.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reducing exploration due to stagnation (entropy coef: 0.013)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training REINFORCE Agent:  57%|█████▋    | 1700/3000 [14:12<07:44,  2.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1700/3000 | Max reward: 87.00 | Avg reward: 1.61 | Recent avg: 1.33 | Consistency ratio: 0.04 | Entropy coef: 0.013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training REINFORCE Agent:  57%|█████▋    | 1711/3000 [14:21<42:30,  1.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max reward: 94.00 at episode 1711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training REINFORCE Agent:  59%|█████▉    | 1769/3000 [15:01<45:58,  2.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best recent average: 3.41 (consistency ratio: 0.04)\n",
      "Model saved to ./models/models_o1/reinforce_best.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training REINFORCE Agent:  60%|█████▉    | 1785/3000 [15:10<25:40,  1.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best recent average: 3.57 (consistency ratio: 0.04)\n",
      "Model saved to ./models/models_o1/reinforce_best.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training REINFORCE Agent:  60%|█████▉    | 1789/3000 [15:17<37:08,  1.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best recent average: 4.09 (consistency ratio: 0.04)\n",
      "Model saved to ./models/models_o1/reinforce_best.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training REINFORCE Agent:  60%|██████    | 1800/3000 [15:25<13:33,  1.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1800/3000 | Max reward: 94.00 | Avg reward: 1.75 | Recent avg: 4.09 | Consistency ratio: 0.04 | Entropy coef: 0.013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training REINFORCE Agent:  63%|██████▎   | 1900/3000 [16:12<07:46,  2.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1900/3000 | Max reward: 94.00 | Avg reward: 1.74 | Recent avg: 1.49 | Consistency ratio: 0.06 | Entropy coef: 0.013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training REINFORCE Agent:  67%|██████▋   | 2001/3000 [16:54<04:47,  3.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 2000/3000 | Max reward: 94.00 | Avg reward: 1.72 | Recent avg: 1.35 | Consistency ratio: 0.04 | Entropy coef: 0.013\n",
      "Model saved to ./models/models_o1/reinforce_ep2000.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training REINFORCE Agent:  70%|███████   | 2100/3000 [17:35<05:36,  2.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 2100/3000 | Max reward: 94.00 | Avg reward: 1.68 | Recent avg: 1.00 | Consistency ratio: 1.00 | Entropy coef: 0.013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training REINFORCE Agent:  73%|███████▎  | 2200/3000 [18:28<04:31,  2.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 2200/3000 | Max reward: 94.00 | Avg reward: 1.72 | Recent avg: 2.41 | Consistency ratio: 0.03 | Entropy coef: 0.013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training REINFORCE Agent:  76%|███████▋  | 2291/3000 [19:15<04:38,  2.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reducing exploration due to stagnation (entropy coef: 0.010)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training REINFORCE Agent:  77%|███████▋  | 2300/3000 [19:18<04:07,  2.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 2300/3000 | Max reward: 94.00 | Avg reward: 1.72 | Recent avg: 1.81 | Consistency ratio: 0.02 | Entropy coef: 0.010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training REINFORCE Agent:  78%|███████▊  | 2333/3000 [19:41<07:06,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best recent average: 4.59 (consistency ratio: 0.02)\n",
      "Model saved to ./models/models_o1/reinforce_best.pth\n",
      "Max reward: 259.00 at episode 2334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training REINFORCE Agent:  80%|████████  | 2400/3000 [20:48<03:11,  3.14it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 2400/3000 | Max reward: 259.00 | Avg reward: 1.83 | Recent avg: 4.29 | Consistency ratio: 0.02 | Entropy coef: 0.010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training REINFORCE Agent:  80%|████████  | 2405/3000 [20:54<17:04,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best recent average: 4.94 (consistency ratio: 0.02)\n",
      "Model saved to ./models/models_o1/reinforce_best.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training REINFORCE Agent:  80%|████████  | 2413/3000 [21:02<16:55,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best recent average: 5.73 (consistency ratio: 0.02)\n",
      "Model saved to ./models/models_o1/reinforce_best.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training REINFORCE Agent:  83%|████████▎ | 2501/3000 [21:41<09:03,  1.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 2500/3000 | Max reward: 259.00 | Avg reward: 1.89 | Recent avg: 3.37 | Consistency ratio: 0.04 | Entropy coef: 0.010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training REINFORCE Agent:  87%|████████▋ | 2601/3000 [22:32<01:35,  4.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 2600/3000 | Max reward: 259.00 | Avg reward: 1.92 | Recent avg: 2.69 | Consistency ratio: 0.03 | Entropy coef: 0.010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training REINFORCE Agent:  90%|█████████ | 2700/3000 [23:19<02:14,  2.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 2700/3000 | Max reward: 259.00 | Avg reward: 1.94 | Recent avg: 2.39 | Consistency ratio: 0.03 | Entropy coef: 0.010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training REINFORCE Agent:  93%|█████████▎| 2800/3000 [24:08<01:16,  2.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 2800/3000 | Max reward: 259.00 | Avg reward: 1.91 | Recent avg: 1.28 | Consistency ratio: 0.04 | Entropy coef: 0.010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training REINFORCE Agent:  94%|█████████▎| 2808/3000 [24:10<01:06,  2.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max reward: 289.00 at episode 2809\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training REINFORCE Agent:  97%|█████████▋| 2900/3000 [25:37<00:40,  2.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 2900/3000 | Max reward: 289.00 | Avg reward: 1.98 | Recent avg: 3.88 | Consistency ratio: 0.01 | Entropy coef: 0.010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training REINFORCE Agent:  97%|█████████▋| 2914/3000 [25:42<00:38,  2.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reducing exploration due to stagnation (entropy coef: 0.010)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training REINFORCE Agent: 100%|██████████| 3000/3000 [26:36<00:00,  1.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 3000/3000 | Max reward: 289.00 | Avg reward: 2.02 | Recent avg: 3.26 | Consistency ratio: 0.03 | Entropy coef: 0.010\n",
      "Model saved to ./models/models_o1/reinforce_ep3000.pth\n",
      "Training completed. Avg reward: 2.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 9,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 8,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 8,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 8,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 68,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 67,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 31,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 66,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 6,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 50,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 87,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 11,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " ...]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.train(\n",
    "    env=env,\n",
    "    num_episodes=config['num_episodes_train'],\n",
    "    print_freq=config['print_freq'],\n",
    "    save_freq=config['save_freq'],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "366be4a0",
   "metadata": {},
   "source": [
    "## Save Model Weights if Desired\n",
    "#### Highest reward runs during training are automatically saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ada83a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.save_model(\n",
    "    model_path=MODEL_PATH,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aad0ccd",
   "metadata": {},
   "source": [
    "## Evaluate Agent Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b1f0abef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "observation: {'type': 'Kinematics', 'vehicles_count': 10, 'features': ['presence', 'x', 'y', 'vx', 'vy', 'cos_h', 'sin_h'], 'features_range': {'x': [-100, 100], 'y': [-100, 100], 'vx': [-20, 20], 'vy': [-20, 20]}, 'absolute': False, 'sorted': True, 'normalize': True, 'include_road_info': True, 'include_vehicle_info': True, 'include_goal_info': True, 'history_length': 5}\n",
      "action: {'type': 'ContinuousAction', 'continuous': True, 'normalize': True, 'clip_actions': True}\n",
      "simulation_frequency: 10\n",
      "policy_frequency: 10\n",
      "other_vehicles_type: highway_env.vehicle.behavior.IDMVehicle\n",
      "screen_width: 600\n",
      "screen_height: 600\n",
      "centering_position: [0.5, 0.6]\n",
      "scaling: 7.15\n",
      "show_trajectories: False\n",
      "render_agent: True\n",
      "offscreen_rendering: False\n",
      "manual_control: False\n",
      "real_time_rendering: False\n",
      "duration: 100\n",
      "destination: o1\n",
      "controlled_vehicles: 1\n",
      "initial_vehicle_count: 10\n",
      "spawn_probability: 0.6\n",
      "collision_reward: -20.0\n",
      "high_speed_reward: 0.1\n",
      "arrived_reward: 50.0\n",
      "reward_speed_range: [0.0, 3.0]\n",
      "normalize_reward: True\n",
      "offroad_terminal: True\n",
      "safe_distance_reward: -6.0\n",
      "route_reward: 7.0\n",
      "progress_reward: 7.0\n",
      "speed_reward: 3.0\n",
      "lane_following_reward: -1.5\n",
      "turning_reward: 12.0\n",
      "consistency_reward: 0.2\n",
      "vehicle: {'length': 4.5, 'width': 2.0, 'max_speed': 20.0, 'acceleration': 2.0, 'steering': 0.5, 'min_speed': 0.0, 'max_steering_angle': 0.5, 'wheel_base': 2.7, 'max_acceleration': 2.0, 'max_deceleration': 4.0, 'max_steering_speed': 0.5}\n",
      "collision_terminal: True\n",
      "off_road_reward: -5.0\n",
      "lane_keeping_reward: 0.5\n",
      "rewards: {'collision_reward': -20.0, 'high_speed_reward': 0.1, 'arrived_reward': 50.0, 'normalize_reward': True, 'off_road_penalty': -5.0, 'steering_penalty': -0.1, 'acceleration_penalty': -0.05, 'progress_reward': 0.5, 'distance_reward': 0.1, 'speed_reward': 0.2, 'heading_reward': 0.3}\n",
      "termination: {'max_steps': 500, 'min_steps': 30, 'max_off_road_time': 2.0, 'max_collision_time': 1.0}\n"
     ]
    }
   ],
   "source": [
    "eval_env = create_env(\n",
    "    config_filepath=ENV_CONFIG,\n",
    "    render_mode='rgb_array',\n",
    ")\n",
    "eval_env.reset(seed=SEED)\n",
    "\n",
    "# Display env configs\n",
    "for key in eval_env.config.keys():\n",
    "    print(f'{key}: {eval_env.config[key]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0bf63d66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from ./models/models_simple/reinforce_best.pth\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.load_model(\n",
    "    model_path='./models/models_simple/reinforce_best.pth',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "de498d72",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating REINFORCE Agent:   0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected error during evaluation: too many values to unpack (expected 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.evaluate(\n",
    "    env=eval_env,\n",
    "    num_episodes=10,\n",
    "    top_k=5,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
